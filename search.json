[
  {
    "objectID": "repo/micro-g/index.html",
    "href": "repo/micro-g/index.html",
    "title": "Game Theory",
    "section": "",
    "text": "Salut! You can navigate yourself through one of the following topics:\n\nNormal-Form Games\n\nHow to describe a normal-form game? What are the implications?\n\nExtensive-Form Games\n\nWhat can happen if each player takes its turns?\n\nRepeated Games\n\nHow to evaluate strategies when games are repeated finitely or infinitely?\n\nBayesian Games\n\nPlayers are best-responding to their own types and also their counterparts’.\n\nPerfect Bayesian Equilibrium\n\nA new equilibrium system based on beliefs.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro II: Game Theory"
    ]
  },
  {
    "objectID": "repo/micro-g/g4.html",
    "href": "repo/micro-g/g4.html",
    "title": "Bayesian Games",
    "section": "",
    "text": "\\[\n\\def\\BB#1{{\\mathbb{#1}}}\n\\def\\BF#1{{\\mathbf{#1}}}\n\\]\nyedlu, Winter 2024",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro II: Game Theory",
      "Bayesian Games"
    ]
  },
  {
    "objectID": "repo/micro-g/g4.html#bayesian-nash-equilibrium",
    "href": "repo/micro-g/g4.html#bayesian-nash-equilibrium",
    "title": "Bayesian Games",
    "section": "Bayesian Nash Equilibrium",
    "text": "Bayesian Nash Equilibrium\nA Bayesian normal form game can be described as:\n\\[\nG = (N, (S_i), (T_i), (u_i), \\BB{P}).\n\\]\n\n\\(N = \\{1, 2, ..., n\\}\\) be the set of players.\n\\(S_i\\) be the set of actions available to player \\(i \\in N\\).\n\\(T_i\\) be the finite set of types to player \\(i \\in N\\). This is private information to player \\(i\\).\n\\(u_i: S \\times T_i \\to \\BB{R}\\) be \\(i\\)’s utility function representing the preference relation.\n\\(\\BB{P}\\) be the belief, which is a probability measure over types \\(\\BF{t} = (t_1, t_2, ..., t_n)^T\\).\n\n\nBayesian Belief System\nQuestion: If I only learn my type (\\(t_i\\)), what is the probability that other players’ types are \\(\\BB{t}_{-i}\\)?\n\n\nAnswer (Click to Expand)\n\nBy Bayes rule,\n\\[\\begin{aligned}\n  \\BB{P}(t_{-i} \\mid t_i) &= \\frac{\\BB{P}(t_i, t_{-i})}{\\BB{P}(t_i)} \\\\\n  &= \\frac{\\BB{P}(t_i, t_{-i})}{\\sum_{t^{'}_{-i} \\in T_{-i}} \\BB{P}(t_i \\mid t^{'}_{-i})}\n\\end{aligned}\\]\n\n\n\nBayesian NE\nDfn (1) A strategy profile \\(\\sigma = (\\sigma_1, ..., \\sigma_n)\\) is a Bayesian NE if\n\nfor each player \\(i\\)\nand their each type \\(t_i \\in T_i\\)\n\nthe strategy maximizes the expected utility:\n\\[\n\\sum_{t_{-i} \\in T_{-i}} u_i(\\sigma_i (t_i), \\sigma_{-i} (t_{-i}) \\times \\BB{P}(t_{-i} \\mid t_i))\n\\]\nDfn (2) A pure strategy for a player \\(i\\) is a function:\n\\[\n\\sigma_i: T_i \\to S_i\n\\]\nDfn (3) A pooling strategy means that for each and every player, her strategy is fixed regardless of types. In other words, \\(\\sigma_i(t_i) = \\sigma_i\\) for all \\(t_i \\in T_i\\).\n\n\nExample: Cutoff Strategy\nConsider the following normal-form game.\n\n\n\n\nb\ns\n\n\n\n\nB\n\\(2 + t_1, 1\\)\n\\(0, 0\\)\n\n\nS\n\\(0, 0\\)\n\\(1, 2 + t_2\\)\n\n\n\nSuppose \\(t_1\\) and \\(t_2\\) are i.i.d. with \\(t_i \\sim U[0,x]\\) for some arbitrarily small \\(x&gt;0\\).\n\n\nAnswer (Click to Expand)\n\nConsider a cutoff strategy.\n\\[\n\\sigma_1(t_1) =\n  \\begin{cases}\n    B &, t_1 \\geq C_1 \\\\\n    S &, t_1 &lt; C_1\n  \\end{cases}\n\\]\n\\[\n\\sigma_2(t_2) =\n  \\begin{cases}\n    s &, t_2 \\geq C_2 \\\\\n    b &, t_2 &lt; C_2\n  \\end{cases}\n\\]\nPlayer 2 best-responds to player 1’s expected strategy: \\[\\begin{aligned}\n  U_2 (b, \\sigma_1, t_2) &= 1 \\times \\BB{P} \\{\\sigma_1(t_1) = B\\} + 0 \\times \\BB{P} \\{\\sigma_1(t_1) = S\\} \\\\\n  &= 1 \\times \\BB{P} \\{t_1 \\geq C_1\\} + 0 \\times \\BB{P} \\{t_1 &lt; C_1\\} \\\\\n  &= \\frac{x - cC_1}{x} \\\\\n  \\\\\n  U_2 (s, \\sigma_1, t_2) &= 0 \\times \\BB{P} \\{\\sigma_1(t_1) = B\\} + (2 + t_2) \\times \\BB{P} \\{\\sigma_1(t_1) = S\\} \\\\\n  &= 0 \\times \\BB{P} \\{t_1 \\geq C_1\\} + (2 + t_2) \\times \\BB{P} \\{t_1 &lt; C_1\\} \\\\\n  &= \\frac{C_1}{x} \\times (2 + t_2)\n\\end{aligned}\\]\nSuppose \\(\\sigma_2 (t_2) = s\\), then: \\[\\begin{aligned}\n  U_2 (b, \\sigma_1, t_2) & \\leq U_2 (s, \\sigma_1, t_2) \\\\\n  \\\\\n  \\frac{x - C_1}{x} & \\leq \\frac{c_1}{x} \\times (2 + t_2) \\\\\n  t_2 & \\geq \\frac{x}{C_1} - 3 \\\\\n  \\\\\n  \\implies C_2 &= \\frac{x}{C_1} - 3\n\\end{aligned}\\]\nSimilarly for player 1, her cutoff point is: \\[\\begin{aligned}\n  C_1 &= \\frac{x}{C_2} - 3\n\\end{aligned}\\]\nSolving the system \\[\\begin{cases}\n  C_1 &= \\frac{x}{C_2} - 3 \\\\\n  C_2 &= \\frac{x}{C_1} - 3\n\\end{cases}\\]\nyields \\[\\begin{aligned}\n  C_1 = C_2 = \\frac{\\sqrt{9 + 4x} - 3}{2}\n\\end{aligned}\\]\nIf the maximum payoff shock shrinks to 0, \\[\\begin{aligned}\n  \\lim_{x \\to 0^+} \\BB{P} \\{\\sigma_1 (t_1) = B\\} &= \\lim_{x \\to 0^+} \\frac{x - C_1}{x} \\\\\n  &= \\lim_{x \\to 0} 1 + \\frac{3 - \\sqrt{9 + 4x}}{2x} \\\\\n  &= \\frac{2}{3} \\quad \\text{(L'Hôpital Rule)}\n\\end{aligned}\\]\n\n\n\nExample: First Price Auctions",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro II: Game Theory",
      "Bayesian Games"
    ]
  },
  {
    "objectID": "repo/micro-g/g2.html",
    "href": "repo/micro-g/g2.html",
    "title": "Extensive-Form Games",
    "section": "",
    "text": "\\[\n\\def\\BB#1{{\\mathbb{#1}}}\n\\def\\BF#1{{\\mathbf{#1}}}\n\\]\nyedlu, Winter 2024\nNormal-form games are one of the more simple form of games to study. One of the stringent assumption we’re going to relax now is that players simultaneously choose their actions; rather, now players take turns. We will dive into this concept deeper with an example.",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro II: Game Theory",
      "Extensive-Form Games"
    ]
  },
  {
    "objectID": "repo/micro-g/g2.html#the-extensive-form-game",
    "href": "repo/micro-g/g2.html#the-extensive-form-game",
    "title": "Extensive-Form Games",
    "section": "The Extensive-Form Game",
    "text": "The Extensive-Form Game\n\nNotation\nThe game:\n\\[\\begin{aligned}\n  \\Gamma = (N, H, P, (u_i))\n\\end{aligned}\\]\nhas\n\nplayers \\(N = \\{1, ..., n\\}\\).\nset of histories \\(H = \\{\\emptyset, ...\\}\\). \\(Z \\subsetneq H\\) is the set of terminal histories, which are not proper subsequenses of any other history. The game ends at \\(z_j \\in Z\\).\nplayer function \\(P: H \\setminus Z \\to N\\) which decides who moves at this history node conditioning on this specific history.\npreference with a utility function \\(u_i: Z \\to \\BB{R}\\) representing it.\n\nIntuition: now there’s a set \\(H\\) that serves as a memory. The function \\(P\\) sees the current history of the game (what happened in the past) and dictates one of the players that now it’s their turn. The game alternates between players in \\(N\\) and ends when it reaches one of the terminal nodes \\(z \\in Z\\).\n\n\nStrategy Profile\nStrategy profiles in extensive-form games must be a full-contingent plan. In other words, \\(\\sigma_i(h) \\neq \\emptyset\\) as long as \\(P(h) = i\\).",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro II: Game Theory",
      "Extensive-Form Games"
    ]
  },
  {
    "objectID": "repo/micro-g/g2.html#subgame-perfect-nash-equilibrium-spne",
    "href": "repo/micro-g/g2.html#subgame-perfect-nash-equilibrium-spne",
    "title": "Extensive-Form Games",
    "section": "Subgame Perfect Nash Equilibrium (SPNE)",
    "text": "Subgame Perfect Nash Equilibrium (SPNE)\nWe will see in a later example that a Nash Equilibrium is not always optimal if we zoom in to a subgame.\n\nSubgames\nDefinition\nA subgame starting at a non-terminal history \\(h \\in H\\) of an extensive-form game of perfect information is another game which:\n\nhas same set of players \\(N\\);\nincludes every history \\(h'\\) such that \\((h, h')\\) is a history of the original game;\nplayer function and preferences are “imported” fro the original game.\n\nConsider we truncate the full game tree at one particular node. The new game tree (prune) is a proper subgame.\n\n\nSubgame Perfect NE\nDefinition\nAn NE of an extensive-form game of perfect information is a subgame-perfect Nash Equilibrium if it induces a NE in every one of its subgames.\n\n\nHow to find SPNE?\nWe can use backward induction to find subgame perfect Nash Equilibrium (SPNE). The general algorithms can be written as:\n\nstart with the smallest possible subgame (length \\(l = k\\) where \\(k = 1\\)) and best-respond them,\nmove to subgames with length \\(l = k + 1\\), and best-respond them conditioning on actions chosen when length \\(l = k\\),\nrepeat and end till the initial node is reached.\n\n\n\nProperties of SPNE Solution\nClaim\nEvery backward induction solution is a Nash Equilibrium.\nIntuition: SPNE \\(\\subset\\) NE.\nProposition\nA pure strategy profile is subgame perfect NE i.i.f. it is a backward induction solution.",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro II: Game Theory",
      "Extensive-Form Games"
    ]
  },
  {
    "objectID": "repo/micro-g/g2.html#example-bach-or-stravinsky-in-extensive-form",
    "href": "repo/micro-g/g2.html#example-bach-or-stravinsky-in-extensive-form",
    "title": "Extensive-Form Games",
    "section": "Example: Bach or Stravinsky in Extensive Form",
    "text": "Example: Bach or Stravinsky in Extensive Form\nThis game has\n\nplayers \\(N = \\{1, 2\\}\\).\nset of histories \\(H = \\{\\emptyset, (B), (S), (B, b), (B, s), (S, b'), (S, s')\\}\\)\nplayer function:\n\n\\(P(\\emptyset) = 1\\)\n\\(P(B) = P(S) = 1\\)\n\na Bernoulli utility function representing utility.\n\nWe would have the following payoff matrix. First we attempt to find all pure strategy NE (bold).\n\n\n\n\nbb’\nbs’\nsb’\nss’\n\n\n\n\nB\n2,1\n2,1\n0,0\n0,0\n\n\nS\n0,0\n1,2\n0,0\n1,2\n\n\n\nHowever, after the notion of subgame perfection, we will try to solve the game with one subgame-perfect Nash Equilibrium.\n\n\nClick to Explore\n\nStarting from subgames with length \\(l = 1\\) and let player 2 best-responds to them:\n\\[\\begin{aligned}\n  \\BB{E}[u_2(b \\mid B)] &= 1 &gt; \\BB{E}[u_2(s \\mid B)] = 0 \\\\\n  \\implies B_2(B) &= b \\\\\n  \\\\\n  \\BB{E}[u_2(s' \\mid S)] &= 2 &gt; \\BB{E}[u_2(b' \\mid S)] = 0 \\\\\n  \\implies B_2(S) &= s'\n\\end{aligned}\\]\nConditioning on this information, player 1 best-responds:\n\\[\\begin{aligned}\n   \\BB{E}[u_1(B \\mid B_2(S_1))] &= 2 \\\\\n   &gt; \\BB{E}[u_1(S \\mid B_2(S_1))] &= 1 \\\\\n  \\implies B_1(\\emptyset) &= B\n\\end{aligned}\\]\nHence, the subgame-perfect Nash Equilibrium (and the only SPNE) is:\n\\[\\begin{aligned}\n   (\\sigma_1 = B, (\\sigma_2(B) = b, \\sigma_2(S) = s'))\n\\end{aligned}\\]\nRemember that a strategy is a full-contingent plan: there must be a suggested action \\(\\sigma_i(h)\\) for every possible history that requires player \\(i\\) to make choices.",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro II: Game Theory",
      "Extensive-Form Games"
    ]
  },
  {
    "objectID": "repo/micro-g/g2.html#example-cournots-duopoly-in-extensive-form-stackelberg-duopoly",
    "href": "repo/micro-g/g2.html#example-cournots-duopoly-in-extensive-form-stackelberg-duopoly",
    "title": "Extensive-Form Games",
    "section": "Example: Cournot’s Duopoly in Extensive Form (Stackelberg Duopoly)",
    "text": "Example: Cournot’s Duopoly in Extensive Form (Stackelberg Duopoly)\nNow, instead of two firms simultaneously choose the production level, we arbitrarily let firm 1 chooses first. After firm 2 observes their counterpart’s decision, they will best-response.\nWe will try to find a subgame-perfect NE (SPNE) using backward induction.\n\n\nClick to Explore\n\nFor the sake of simplicity we first assume that \\(q_i \\leq 1\\) for all \\(i\\).\nStarting from the subgame with length \\(l = 1\\) and let firm 2 best-responds:\n\\[\\begin{aligned}\n  u_2 &= q_2 (1 - q_1 - q_2)\n\\end{aligned}\\]\nFirst-Order Condition (FOC) gives that:\n\\[\\begin{aligned}\n  1 - q_1 - 2 q_2^* &= 0 \\\\\n  B_2(q_1) = q_2^* &= \\frac{1 - q_1}{2}\n\\end{aligned}\\]\nThen player 1 is aware of this information and best-responds:\n\\[\\begin{aligned}\n  u_1 &= q_1 (1 - q_1 - q_2) \\\\\n  &= q_1 (1 - q_1 - \\frac{1 - q_1}{2}) \\\\\n  &= \\frac{q_1 (1-q_1)}{2}\n\\end{aligned}\\]\nFirst-Order Condition (FOC) gives that:\n\\[\\begin{aligned}\n  \\frac{1}{2} - q_1^* &= 0 \\\\\n  B_1(q_2) = q_1^* &= \\frac{1}{2}\n\\end{aligned}\\]\nThe subgame-perfect Nash Equilibrium for this game is then:\n\\[\\begin{aligned}\n  (q_1 = \\frac{1}{2}, q_2 = \\frac{1}{4})\n\\end{aligned}\\]",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro II: Game Theory",
      "Extensive-Form Games"
    ]
  },
  {
    "objectID": "repo/micro-u/u3.html",
    "href": "repo/micro-u/u3.html",
    "title": "Von Neumann-Morgenstern Expected Utility",
    "section": "",
    "text": "yedlu, Fall 2024",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro I: Utility Theory",
      "vNM Axioms"
    ]
  },
  {
    "objectID": "repo/micro-u/u3.html#intro-to-lotteries-an-extra-layer-of-uncertainty",
    "href": "repo/micro-u/u3.html#intro-to-lotteries-an-extra-layer-of-uncertainty",
    "title": "Von Neumann-Morgenstern Expected Utility",
    "section": "Intro to Lotteries: an Extra Layer of Uncertainty",
    "text": "Intro to Lotteries: an Extra Layer of Uncertainty\n\nThe individual must choose an action with uncertain outcomes. The individual has preference over final consequences.\n\\(X = \\{x_1, ..., x_n\\}\\) be the finite set of consequences\n\\(p = (p_1, ..., p_n), p_i \\geq 0, \\Sigma_i p_i = 1\\) be the lottery on \\(X\\)\n\\(\\Delta(X) = \\{p \\in \\mathbb{R}^n_+: \\Sigma_i p_i = 1\\}\\) be the set of lotteries on \\(X\\)\n\\(\\succsim \\subseteq \\Delta(X) \\times \\Delta(X)\\) be the binary preference relations on the set of lotteries \\(\\Delta(X)\\)\n\n\nMixing Lotteries\nGiven two lotteries \\(p, q \\in \\Delta(X)\\) and a weight \\(\\alpha \\in [0,1]\\), define the lottery\n\\[\\alpha p + (1-\\alpha) q := (\\alpha p_1 + (1-\\alpha) q_1, ..., \\alpha p_n + (1-\\alpha) q_n)\\]\n\n\nSpecial Lotteries with Certain Outcomes\nDefine certainty lotteries as \\(\\delta_i = (p_1, ..., p_n)\\) with \\(p_i = 1\\). Specifically, \\(\\delta_1 = (1,...,0)\\) and \\(\\delta_n = (0, ..., 1)\\).\n\n\nExpected Utility Functions\nGiven a utility function over consequences \\(u: X \\to \\mathbb{R}\\), we may evaluate lotteries \\(p = (p_1, ..., p_n)\\) by its expected utility:\n\\[U(p) := p_1 u(x_1) + ... + p_n u(x_n)\\]\n\nThe \\(U: \\Delta(X) \\to \\mathbb{R}\\) is said to have the expected utility form.\nThe \\(u: X \\to \\mathbb{R}\\) is called a Bernoulli payoff function.\n\n\n\nLinear and Expected Utility\nLemma. The following two statements are logically equivalent.\n\n\\(U\\) is linear if for every \\(p, q \\in \\Delta(X)\\) and every \\(\\alpha \\in [0,1]\\): \\[U[\\alpha p + (1-\\alpha)q] = \\alpha U(p) + (1-\\alpha) U(q)\\]\n\\(U\\) is in expected utility form if there exists \\(u: X \\to \\mathbb{R}\\) such that: \\[U(p) = \\sum_{x \\in X} u(x) p(x)\\] for every \\(p \\in \\Delta(X)\\)\n\n\n\nProof (Click to Expand)\n\nParts of proof: \\(2 \\Rightarrow 1\\). \\[\\begin{aligned}\n      U[\\alpha p + (1-\\alpha) q] &= U(\\alpha p_1 + (1-\\alpha) q_1, ..., \\alpha p_n + (1-\\alpha) q_n) \\\\\n      &= \\Sigma_{i=1}^n u(x_1) [\\alpha p_1 + (1-\\alpha) q_1] \\\\\n      &= \\alpha \\Sigma_{i=1}^n u(x_1) p_1 + (1-\\alpha) \\Sigma_{i=1}^n u(x_1) q_1 \\\\\n      &= \\alpha U(p) + (1-\\alpha) U(q)\n\\end{aligned}\\]\n\\(\\blacksquare\\)\n\n\n\nThe von Neumann-Morgenstern (vNM) Axioms\nLet \\(\\succsim\\) be a binary relation on the set of lotteries \\(\\Delta(X)\\). - Axiom 1 (rational): \\(\\succsim\\) is complete and transitive. - Axiom 2 (continuous): for every \\(p, q, r \\in \\Delta(X)\\) with \\(p \\succ q \\succ r\\), there exists \\(\\alpha, \\beta \\in (0,1)\\) such that: \\(\\alpha p + (1-\\alpha) r \\succ q \\succ \\beta p + (1 - \\beta) r\\). - Axiom 3 (independence): for every \\(p, q, r \\in \\Delta(X)\\) and every \\(\\alpha \\in (0,1)\\), we have \\(p \\succ q\\) if and only if:\n\\[\\alpha p + (1-\\alpha) r \\succ \\alpha q + (1-\\alpha) r\\]\n\nThe vNM Representation Theorem\nThe following statements are logically equivalent: 1. \\(\\succsim\\) satisfies Axioms 1, 2, and 3; 2. There exists a linear function \\(U: \\Delta(X) \\to \\mathbb{R}\\) that represents \\(\\succsim\\).\n\n\nThe Uniqueness Proposition\nSuppose \\(U, V: \\Delta(X) \\to \\mathbb{R}\\) are linear functions. Suppose \\(U\\) represents \\(\\succsim\\). Then \\(V\\) also represents \\(\\succsim\\) iif there exists \\(\\alpha &gt; 0\\) and \\(\\beta \\in \\mathbb{R}\\) such that \\(V = \\alpha U + \\beta\\).",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro I: Utility Theory",
      "vNM Axioms"
    ]
  },
  {
    "objectID": "repo/micro-u/u2.html",
    "href": "repo/micro-u/u2.html",
    "title": "Choices/Preference/Utility over Infinite Outcomes",
    "section": "",
    "text": "yedlu, Fall 2024",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro I: Utility Theory",
      "Infinite Outcomes"
    ]
  },
  {
    "objectID": "repo/micro-u/u2.html#recap-finite-chocices",
    "href": "repo/micro-u/u2.html#recap-finite-chocices",
    "title": "Choices/Preference/Utility over Infinite Outcomes",
    "section": "Recap: Finite Chocices",
    "text": "Recap: Finite Chocices\n\n\\(X = \\mathbb{R}^n_+\\) be finite choices\n\\(c: P(X) \\to X\\) be the choice function\n\\(\\succsim\\) be the preference relation\n\\(U: \\mathbb{R}^n_+ \\to \\mathbb{R}\\) be the corresponding utility function.\n\n\nWhat if Choices Become Infinite\n\nDifferent Levels of Finite\n\nFinite: there exists a bijection \\(X \\leftrightarrow \\{1, ..., n\\}\\).\n\neach \\(x \\in X\\) is paired with exactly one number in \\(\\{1, ..., n\\}\\)\neach number in \\(\\{1, ..., n\\}\\) is paired with exactly one \\(x \\in X\\)\nnobody is left unpaired\n\nCountably Infinite: there exists a bijection \\(X \\leftrightarrow \\mathbb{N} = \\{1, 2, ...\\}\\). Below are number sets by their finiteness\n\n\\(\\mathbb{Z} = \\{..., -1, 0, 1, ...\\}\\) is countably infinite\n\\(\\mathbb{Q} = \\{a/b: a \\in \\mathbb{Z}, b \\in \\mathbb{N}\\}\\) is countably infinite\n\\(\\mathbb{R}\\) is not countably infinite\n\n\n\n\nCountable Infinite\nProposition. \\(\\succsim\\) be a rational preference and \\(X\\) be a countable set \\(\\Rightarrow\\) there exists \\(U: X \\to \\mathbb{R}\\) representing \\(\\succsim\\).\n\n\nProof (Click to Expand)\n\nConsider:\n\na countable choice set: \\(X = \\{x_1, ..., x_n, ...\\}\\).\na weight indicator: \\(d_j = \\frac{1}{2^j}\\).\n\nWe would have \\[\\begin{aligned}\n      \\Sigma_{j=1}^{\\infty} d_j = \\Sigma_{j=1}^{\\infty} \\frac{1}{2^j} = \\lim_{n \\to \\infty} [\\Sigma_{j = 1}^n \\frac{1}{2^j}] = 1\n\\end{aligned}\\]\nWe can define the utility function \\(U: X \\to \\mathbb{R}\\) as \\[\\begin{aligned}\n      U(z) = \\Sigma_{\\{j \\in \\mathbb{N}: (z, x_j) \\in \\succsim\\}} d_j\n\\end{aligned}\\]\n\\(\\blacksquare\\)\n\n\n\n\nIncountable Infinite\nIt is not always true that there exists a utility function \\(U: X \\to \\mathbb{R}\\) to represent a rational \\(\\succsim\\).\nE.g. Bowser Jr.’s Lexicographic Preferences (\\(X = \\mathbb{R}^2_+\\)).\nWe would need some other properties that \\(\\succsim\\) must satisfy to make the utility function possible.",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro I: Utility Theory",
      "Infinite Outcomes"
    ]
  },
  {
    "objectID": "repo/micro-u/u2.html#continuous-preference-relation",
    "href": "repo/micro-u/u2.html#continuous-preference-relation",
    "title": "Choices/Preference/Utility over Infinite Outcomes",
    "section": "Continuous Preference Relation",
    "text": "Continuous Preference Relation\nDefinition: for all pairs \\(x,y \\in X\\) with \\(x \\succ y\\), we can always find \\(\\epsilon &gt; 0\\) such that: - \\(|x - x'| &lt; \\epsilon\\) - \\(|y - y'| &lt; \\epsilon\\)\nimplies \\(x' \\succ y'\\).\nIntuition: a strictly preferred pair should remain their preference status even under a sligtest change in any direction. We would not expect a rational person to freak out if a slightest change takes place.\n\nUtility Representation\nProposition. If \\(\\succsim\\) is complete, transitive, and continuous, then there exists a continuous \\(U: \\mathbb{R}^n_+ \\to \\mathbb{R}\\) that represents \\(\\succsim\\).",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro I: Utility Theory",
      "Infinite Outcomes"
    ]
  },
  {
    "objectID": "repo/micro-u/u5.html",
    "href": "repo/micro-u/u5.html",
    "title": "Afriat’s Theorem",
    "section": "",
    "text": "* in conjunction with §4 of Microeconomics Foundation I (Kreps 2013)\nyedlu, Fall 2024",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro I: Utility Theory",
      "Afriat's Theorem"
    ]
  },
  {
    "objectID": "repo/micro-u/u5.html#notations",
    "href": "repo/micro-u/u5.html#notations",
    "title": "Afriat’s Theorem",
    "section": "Notations",
    "text": "Notations\n\n\\(X = \\mathbb{R}^{n}_{+}\\) be consumption bundles. A vector with \\(n\\) non-negative elements.\n\\(B(p,m) = \\{x \\in X: p \\cdot x \\leq m\\}\\) be the budget set.\n\\(c(B(p,m))\\) be the demand chosen by the consumer.\n\nKey: what to infer from finite number of actual choices?",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro I: Utility Theory",
      "Afriat's Theorem"
    ]
  },
  {
    "objectID": "repo/micro-u/u5.html#concepts-and-assumptions",
    "href": "repo/micro-u/u5.html#concepts-and-assumptions",
    "title": "Afriat’s Theorem",
    "section": "Concepts and Assumptions",
    "text": "Concepts and Assumptions\n\nLocally Insatiable\nFor every bundle \\(x \\in X\\), for every \\(\\epsilon &gt; 0\\), there exists \\(y \\in X\\) with \\(|x-y| &lt; \\epsilon\\) and \\(y \\succ x\\).\nIntuition: a consumer would always accept if they are provided a bundle with slightly more stuff.\nLemma\nIf \\(\\succsim\\) is complete, transitive, locally insatiable; \\(x^*\\) is chosen from the budget set \\(B(p,m)\\), then\n\n\\(x^* \\succsim x\\) for all \\(x\\) with \\(p \\cdot x = m\\)\n\\(x^* \\succ x\\) for all \\(x\\) with \\(p \\cdot x &lt; m\\).\n\n\n\nGARP (Generalized Axioms of Revealed Preferences)\nGiven a finite dataset:\n\np = (\\(p^1, ..., p^n\\)) as the price vector\nm = (\\(m^1, ..., m^n\\)) as the income/budget vector\nx = (\\(x^1, ..., x^n\\)) as the choice vector\n\nwith \\(p^i \\cdot x^i \\leq m^i\\) for each \\(i\\), we say that:\n\n\\(x^i \\succsim^d x^j\\) when \\(p^i \\cdot x^j \\leq m^i\\)\n\\(x^i \\succ^d x^j\\) when \\(p^i \\cdot x^j &lt; m^i\\)\n\\(x^i \\succsim^R x^j\\) when \\(x^i \\succsim^d x \\succsim^d ... \\succsim^d x^j\\)\n\\(x^i \\succ^R x^j\\) when \\(x^i \\succsim^d ... \\succ^d x \\succsim^d ... \\succsim^d x^j\\)\n\nThe dataset satistify GARP if \\(x^i \\not\\succ^R x^i\\) for every \\(i\\).\n\n\nStrictly Increasing Preference\nThe preference \\(\\succsim \\subseteq \\mathbb{R}^n_+ \\times \\mathbb{R}^n_+\\) is strictly increasing if\n\n\\(x_i \\geq y_i\\) for all \\(i\\)\n\\(x \\neq y\\)\n\nimplies \\(x \\succ y\\). This \\(\\succsim\\) is automatically locally insatiable.\n\n\nConvex Preference\nThe preference \\(\\succsim \\subseteq \\mathbb{R}^n_+ \\times \\mathbb{R}^n_+\\) is convex if\n\n\\(x \\succsim y\\)\n\\(\\alpha \\in [0,1]\\)\n\nimplies \\(\\alpha x + (1-\\alpha) y \\succsim y\\).",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro I: Utility Theory",
      "Afriat's Theorem"
    ]
  },
  {
    "objectID": "repo/micro-u/u5.html#afriats-theorem",
    "href": "repo/micro-u/u5.html#afriats-theorem",
    "title": "Afriat’s Theorem",
    "section": "Afriat’s Theorem",
    "text": "Afriat’s Theorem\n\nIf dataset violates GARP, then there cannot exist a complete, transitive, and locally insatiable \\(\\succsim\\) with \\(x^i \\in c_{\\succsim}(B(p^i, m^i))\\).\nIf dataset satisfies GARP, then there exists a complete, transitive, locally insatiable, strictly increasing, continuous, convex \\(\\succsim\\) with \\(x^i \\in c_{\\succsim}(B(p^i, m^i))\\).\n\n\n\nProof of 1\n\nSuppose we have a complete, transitive, and locally insatiable \\(\\succsim\\) with \\(x^i \\in c_{\\succsim}(B(p^i, m^i))\\) for each \\(i = 1, ..., n\\).\nIf we had a GARP violation, then \\(x^i \\succ^R x^i\\). This implies that:\n\\[x^i \\succsim^d ... \\succsim^d x^j \\succ^d x^k \\succsim^d ... \\succsim^d x^i\\]\n\\[\\Rightarrow x^i \\succsim ... \\succsim x^j \\succ x^k \\succsim ... \\succsim x^i\\]\n\\(\\Rightarrow x^i \\succ x^i\\), which leads to a contradiction.",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro I: Utility Theory",
      "Afriat's Theorem"
    ]
  },
  {
    "objectID": "repo/micro-u/u5.html#proof-of-2-afriats-approach-to-constructing-utility",
    "href": "repo/micro-u/u5.html#proof-of-2-afriats-approach-to-constructing-utility",
    "title": "Afriat’s Theorem",
    "section": "Proof of 2 (Afriat’s Approach to Constructing Utility)",
    "text": "Proof of 2 (Afriat’s Approach to Constructing Utility)\nSuppose data \\((p, m, x)\\) satisfies \\(p^i \\cdot x^i \\leq m^i\\) and GARP.\n\n\\(p^i \\cdot x^i = m^i\\) for all \\(i\\).\n\nIntuition: Every choice must be preference-maximizing under budget constraint. If not, then there must be a better choice under this price \\(p\\) and budget constraint \\(m\\).\n\n\nProof\n\nAssume to contrary that \\(p^i \\cdot x^i &lt; m^i\\). Then by GARP, \\(x^i \\succ^d x^i\\), which implies that \\(x^i \\succ^R x^i\\), which creates a contradiction by violates GARP.\n\n\n\\(|\\{x^k: x^i \\succ^R x^k\\}| &lt; |\\{x^k: x^j \\succ^R x^k\\}| \\Rightarrow p^i \\cdot x^j &gt; m^i\\).\n\nIntuition: A choice \\(x^j\\) strictly more superior than the other choice \\(x^i\\) should never be feasible under the condition where \\(x^i\\) was chosen. If not, then the choice should be \\(x^j\\) instead of \\(x^i\\).\n\n\nProof\n\nIf \\(p^i \\cdot x^j \\leq m^i\\), then according to GARP, \\(x^i \\succsim^d x^j\\). Then, \\(\\{x^k: x^j \\succ^R x^k\\} \\subseteq \\{x^k: x^i \\succ^R x^k\\}\\), which contradicts \\(\\{x^k: x^i \\succ^R x^k\\}| &lt; |\\{x^k: x^j \\succ^R x^k\\}|\\).\n\n\n\\(|\\{x^k: x^i \\succ^R x^k\\}| \\leq |\\{x^k: x^j \\succ^R x^k\\}| \\Rightarrow p^i \\cdot x^j \\geq m^i\\).\n\nIntuition: A choice \\(x^j\\) at least as good as the other choice \\(x^i\\) should never be strictly inferior when under price and budget constraint of \\(x^i\\).\n\n\nProof\n\nAssume to contrary that \\(p^i \\cdot x^j &lt; m^i\\). Then it implies that \\(x^i \\succ^d x^j\\). Also by GARP, \\(x^j \\in \\{x^k: x^i \\succ^R x^k\\}\\) and \\(x^j \\in \\{x^k: x^i \\succ^R x^k\\}\\). Thus, \\(\\{x^k: x^j \\succ^R x^k\\} \\subsetneq \\{x^k: x^i \\succ^R x^k\\}\\), contradicting the assumption.\n\n\n\\(\\exists x^k: \\forall i \\quad x^k \\not\\succ^R x^i\\)\n\nIntuition: there must be a lowest-ranking choice that is never strictly prefered to any other choices. If not, there will exist a loop that violates transitivity.\n\n\nProof\n\nSuppoose for all \\(x^k\\), there exists \\(x^i\\) such that \\(x^k \\succ^R x^i\\). Then it must be the case that the following chain with \\(2n+1\\) elements: \\(x^1 \\succ x^{j1} \\succ x^{j2} \\succ ... \\succ x^{j2n}\\). Since we are in a finite set with \\(n\\) choice bundles, there must be somewhere, in between, that \\(x^k \\succ x^k\\) happens, which directly violates GARP.\n\n\n\\(\\exists \\, v^1, ..., v^n \\in \\mathbb{R} \\quad \\exists \\, \\alpha^1, ..., \\alpha^n &gt; 0 \\quad \\forall i, j \\quad v^i \\leq v^j + \\alpha^j [p^j x^i - p^j x^j]\\)\n\nIntuition: we want to use \\(v^j\\) as the baseline of utility. \\(\\alpha^j\\) controls the speed of moving the baseline.\n\n\nProof\n\nBy induction. When \\(n=1\\), let \\(v^1 = 0\\) and \\(\\alpha^1 = 1\\). Suppose this is true when we have \\(n\\) choices. Now, denote \\(x^{n+1}\\) as \\(x^{n+1} \\not\\succ^R x^i\\) for every \\(i\\). We can imply from the assumption that this statement is true for observation \\(1, ..., n\\) that:\n\\[\\exists \\, v^1, ..., v^n \\in \\mathbb{R} \\quad \\exists \\, \\alpha^1, ..., \\alpha^n &gt; 0 \\quad \\forall i, j \\quad v^i \\leq v^j + \\alpha^j [p^j x^i - p^j x^j].\\]\nDefine: \\(v^{n+1} = \\min_{1 \\leq j \\leq n} v^j + \\alpha^j [p^j x^{n+1} - p^j x^j]\\). Since \\(|\\{x^k: x^{n+1} \\succ^R x^k\\}| = 0\\), we can say that \\(p^{n+1} x^j \\geq m^{n+1} = p^{n+1} x^{n+1}\\) for every \\(1 \\leq j \\leq n\\).\nWe assert that for \\(1 \\leq j \\leq n\\), either \\(p^{n+1} x^j &gt; m^{n+1} = p^{n+1} x^{n+1}\\) or \\(p^{n+1} x^j = m^{n+1} = p^{n+1} x^{n+1}\\) holds.\n\nIf \\(p^{n+1} x^j &gt; m^{n+1} = p^{n+1} x^{n+1}\\), \\(p^{n+1} x^j - p^{n+1} x^{n+1} &gt; 0\\). Then there exists \\(\\alpha^{n+1} &gt; 0\\) large enough such that \\(v^j \\leq v^{n+1} + \\alpha^{n+1} [p^{n+1} x^j - p^{n+1} x^{n+1}]\\) holds.\n\nIf \\(p^{n+1} x^j = m^{n+1} = p^{n+1} x^{n+1}\\), \\(p^{n+1} x^j - p^{n+1} x^{n+1} = 0\\).\n\nThen, as long as \\(\\alpha^{n+1} \\in \\mathbb{R}_{++}\\), \\(v^j \\leq v^{n+1} + \\alpha^{n+1} [p^{n+1} x^j - p^{n+1} x^{n+1}] = v^{n+1}\\) holds.\n\n\nLet \\(u(x) := \\min_{1 \\leq j \\leq n} v^i + \\alpha^i [p^i x - p^i x^i]\\).\n\nIntuition: this function yields a concave form.",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro I: Utility Theory",
      "Afriat's Theorem"
    ]
  },
  {
    "objectID": "repo/micro-u/u5.html#application-giffin-goods",
    "href": "repo/micro-u/u5.html#application-giffin-goods",
    "title": "Afriat’s Theorem",
    "section": "Application: Giffin Goods",
    "text": "Application: Giffin Goods\n\nNormal goods: \\(p_i \\uparrow \\quad \\Rightarrow x^i \\downarrow\\)\nGiffin goods: \\(p_i \\uparrow \\quad \\Rightarrow x^i \\uparrow\\)\n\nOne application of Afriat’s theorem is prooving the existance of Giffin goods. Since an individual with observable Giffin goods purchasing behavior does not necessarily violate GARP, then there exists a preference relation that is complete, transitive, locally insatiable, continuous, strictly increasing, and convex that generates it.",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro I: Utility Theory",
      "Afriat's Theorem"
    ]
  },
  {
    "objectID": "repo/micro-u/u6.html",
    "href": "repo/micro-u/u6.html",
    "title": "Stochastic Choice",
    "section": "",
    "text": "* in conjunction with §5 of Microeconomics Foundation I (Kreps 2013)\nyedlu, Fall 2024",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro I: Utility Theory",
      "Stochastic Choice"
    ]
  },
  {
    "objectID": "repo/micro-u/u6.html#stochastic-random-choice",
    "href": "repo/micro-u/u6.html#stochastic-random-choice",
    "title": "Stochastic Choice",
    "section": "Stochastic (Random) Choice",
    "text": "Stochastic (Random) Choice\n\nBinary Random Choice Rule\n\n\n\\(X \\neq \\emptyset\\) be the universe of alternatives.\n\\(\\rho: X \\times X \\to [0,1]\\) be the binary random choice rule if \\(\\rho(x,y) + \\rho(y,x) = 1\\) for all \\(x,y \\in X\\).\n\n\nRandom Choice Rule\n\n\n\\(P(X)\\) be the nonempty finite subset of \\(X\\).\n\\(\\rho: X \\times P(X) \\to [0,1]\\) be the random choice rule if \\(\\sum_{x \\in A} \\, \\rho(x, A) = 1\\) for all \\(A \\in \\mathcal{A}\\).\n\nNotation \\(\\rho(x, A = \\{x,y\\})\\) is equivalent to \\(\\rho(x,y)\\).",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro I: Utility Theory",
      "Stochastic Choice"
    ]
  },
  {
    "objectID": "repo/micro-u/u6.html#random-utility-and-random-preference",
    "href": "repo/micro-u/u6.html#random-utility-and-random-preference",
    "title": "Stochastic Choice",
    "section": "Random Utility and Random Preference",
    "text": "Random Utility and Random Preference\n\nRandom Preference Model\n\n\\(X = \\{x_1, x_2, ..., x_n\\}\\) be the set of finite choices\n\\(\\mu\\) be the probability over strict rankings on \\(X\\)\n\n\\(\\rho (x_i, A) = \\mu\\{\\succ: \\forall x_j \\in A \\setminus \\{x_i\\} \\quad x_i \\succ x_j\\}\\)\n\n\n\n\nRandom Utility Model (RUM)\n\n\\(X = \\{x_1, x_2, ..., x_n\\}\\) be the set of finite choices\n(\\(\\Omega, \\mathcal{F}, \\mathbb{P}\\)) be the probability space (triple). A quick recap:\n\nSample space \\(\\Omega\\): a set of all possible outcomes.\nEvent space \\(\\mathcal{F}\\): a set containing events. An event is a set of outcomes in sample space.\nProbability function \\(\\mathbb{P}: \\mathcal{F} \\to [0,1]\\): assign a probability to each event. Specifically, \\(\\mathbb{P}\\{\\Omega\\} = 1\\)\n\n\\(U_1, U_2, ..., U_n: \\Omega \\to \\mathbb{R}\\) be random utilities (r.v.) with \\(\\mathbb{P}\\{\\omega \\in \\Omega: U_i(\\omega) = U_j(\\omega), i \\neq j\\} = 0\\).\n\\(\\rho(x_i, A) = \\mathbb{P}\\{\\omega \\in \\Omega: \\forall j \\in A \\quad U_i(\\omega) \\geq U_j(\\omega)\\}\\)\n\n\\(\\mathbb{P}\\{\\omega \\in \\Omega: U_A(\\omega) &gt; U_B(\\omega) &gt; U_C(\\omega)\\} = \\mu\\{A \\succ B \\succ C\\}\\)\n\n\\(U: \\Omega \\to \\mathbb{R}\\) be the random utility function. Its cumulative distribution function (cdf) is: \\[\\begin{aligned}\nF(t) & = \\mathbb{P}\\{\\omega \\in \\Omega: U(\\omega) \\leq t\\} \\\\\n& = \\mathbb{P} \\{U \\leq t\\}\n\\end{aligned}\\]",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro I: Utility Theory",
      "Stochastic Choice"
    ]
  },
  {
    "objectID": "repo/micro-u/u6.html#block-marschak-proposition-1960",
    "href": "repo/micro-u/u6.html#block-marschak-proposition-1960",
    "title": "Stochastic Choice",
    "section": "Block & Marschak Proposition (1960)",
    "text": "Block & Marschak Proposition (1960)\n\\(\\rho\\) is a random preference model if and only if (iif) \\(\\rho\\) is a random utility model. The Block & Marschak Inequalities states necessarily that:\nIf \\(\\rho\\) is a RUM, then:\n\\[q(x,A) = \\sum_{B \\supseteq A} (-1)^{|B \\setminus A|} \\rho(x,B) \\geq 0\\]\nE.g. 1: Given \\(X = \\{x,y,z\\}\\) and \\(A = \\{x,y\\}\\), \\[\\begin{aligned}\n    q(x,A) & = \\sum_{B \\supseteq A} (-1)^{|B \\setminus A|} \\rho(x,B) \\\\\n    & = (-1)^{|X \\setminus A|} \\rho(x,X) + (-1)^{|A \\setminus A|} \\rho(x,A) \\\\\n    & = (-1)^{|\\{z\\}|} \\rho(x,X) + (-1)^{|\\emptyset|} \\rho(x,A) \\\\\n    & = - \\rho(x,X) + \\rho(x,A) \\geq 0 \\\\\n    \\\\\n    & \\Rightarrow  \\rho(x,A) \\geq \\rho(x,X)\n\\end{aligned}\\]\nIntuition: the possibility of choosing an option cannot become greater when new choices emerge. This implies that every \\(\\mu \\in [0,1]\\) and \\(\\sum \\mu = 1\\).\nE.g. 2: Given \\(X = \\{x,y,z,w\\}\\) and \\(A = \\{x,y\\}\\). \\[\\begin{aligned}\n      q(x, A) &= \\sum_{B \\supseteq A} (-1)^{|B \\setminus A|} \\rho(x,B) \\\\\n      &= (-1)^{|A \\setminus A|} \\rho(x,A) + (-1)^{|\\{x,y,z\\} \\setminus A|} \\rho(x,\\{x,y,z\\}) \\\\\n      & \\quad + (-1)^{|\\{x,y,w\\} \\setminus A|} \\rho(x,\\{x,y,w\\}) + (-1)^{|\\{x,y,z,w\\} \\setminus A|} \\rho(x,\\{x,y,z,w\\}) \\\\\n      &=  \\rho(x,X) - \\rho(x,\\{x,y,z\\}) - \\rho(x, \\{x,y,w\\}) + \\rho(x,A) \\geq 0 \\\\\n      \\\\\n      &\\Rightarrow \\rho(x,A) - \\rho(x, \\{x,y,w\\}) \\geq \\rho(x,\\{x,y,z\\}) - \\rho(x,X)\n\\end{aligned}\\]\nIntuition: if we use \\(\\mu\\) in random preference model to denote the results above:\n\\[\\begin{aligned}\n      \\rho(x,A) - \\rho(x, \\{x,y,w\\}) &\\geq \\rho(x,\\{x,y,z\\}) - \\rho(x,X) \\\\\n      \\mu\\{z \\succ w \\succ x \\succ y\\} + \\mu\\{w \\succ z \\succ x \\succ y\\} & \\\\\n      +\\mu\\{w \\succ x \\succ z \\succ y\\} + \\mu\\{w \\succ x \\succ y \\succ z\\} &\\geq \\mu\\{w \\succ x \\succ y \\succ z\\}\n\\end{aligned}\\]\nThis would hold if \\(\\mu \\in [0,1]\\).",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro I: Utility Theory",
      "Stochastic Choice"
    ]
  },
  {
    "objectID": "repo/micro-u/u6.html#falmagnes-theorem-1978",
    "href": "repo/micro-u/u6.html#falmagnes-theorem-1978",
    "title": "Stochastic Choice",
    "section": "Falmagne’s Theorem (1978)",
    "text": "Falmagne’s Theorem (1978)\n\\(\\rho\\) is a RUM iif it satisfies the Block-Marschak inequalities (sufficiently).\nInterpretation of the Block-Marschak inequalities: \\(q(x,A)\\) is the probability that:\n\noptions in \\(X \\setminus A\\) are ranked above \\(x\\), and\n\\(x\\)’s ranking is \\(|X \\setminus A| + 1\\).\n\nExample: Consider \\(X = \\{x,y,z\\}\\) and \\(A = \\{x,y\\}\\). Then \\[\\begin{aligned}\n      q(x,A) &= \\rho(x, A) - \\rho(x,X) \\\\\n      &= \\mu\\{z \\succ x \\succ y\\} + \\mu\\{x \\succ z \\succ y\\} + \\mu\\{x \\succ y \\succ z\\} \\\\\n      & \\quad - \\mu\\{x \\succ z \\succ y\\} + \\mu\\{x \\succ y \\succ z\\} \\\\\n      &= \\mu\\{z \\succ x \\succ y\\}\n\\end{aligned}\\]\nThis is:\n\noptions in \\(X \\setminus A\\) are ranked above \\(x\\) (\\(z\\)), and\n\\(x\\)’s ranking is \\(|X \\setminus A| + 1 = 1 + 1 = 2\\).",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro I: Utility Theory",
      "Stochastic Choice"
    ]
  },
  {
    "objectID": "repo/micro-u/u6.html#some-random-utility-models",
    "href": "repo/micro-u/u6.html#some-random-utility-models",
    "title": "Stochastic Choice",
    "section": "Some Random Utility Models",
    "text": "Some Random Utility Models\n\n1. Logit\n\nForm: \\(U_i = v_i + \\epsilon_i\\), where \\(v_i \\in \\mathbb{R}\\) and \\(\\epsilon_i \\sim\\) Gumbel (iid.)\nGumbel Distribution: - \\(\\mathbb{P} \\{\\epsilon_i \\leq t\\} = F(t) = \\exp[-\\exp(-t)]\\) - Gumbel cdf: \\(F(s) = e^{-e^{-s}} = \\mathbb{P}\\{\\epsilon \\leq s\\}\\) - Gumbel pdf: \\(f(s) = \\frac{d\\,F(s)}{d\\,s} = e^{-s} \\cdot e^{-e^{-s}}\\)\n\nThen, under logit,\n\\[\\begin{aligned}\n  \\rho(x_i, A) & = \\mathbb{P}\\{(\\forall j \\in A, j \\neq i) \\quad U_i &gt; U_j\\} \\\\\n  & = \\mathbb{P}\\{(\\forall j \\in A, j \\neq i) \\quad v_i + \\epsilon_i &gt; v_j + \\epsilon_j\\} \\\\\n  & = \\mathbb{P}\\{\\epsilon_j &lt; (v_i - v_j) + \\epsilon_i\\} \\\\\n  & = \\int_{-\\infty}^{+\\infty} \\Pi_{j \\neq i} \\, F(v_i - v_j + s) f(s)ds \\\\\n  & = \\int_{-\\infty}^{+\\infty} \\Pi_{j \\neq i} e^{-e^{-(v_i - v_j + s)}} \\cdot e^{-s} \\cdot e^{-e^{-s}} ds \\\\\n  & = \\frac{e^{v_i}}{\\sum_{j \\in A} e^{v_j}}\n\\end{aligned}\\]\n\n\n2. Luce\n\\(v: X \\to (0, \\infty)\\) \\(\\rho(x,A) = \\frac{v(s)}{\\sum_{y \\in A} v(y)}\\)",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro I: Utility Theory",
      "Stochastic Choice"
    ]
  },
  {
    "objectID": "repo/micro-u/u6.html#directly-observable-and-testable-transitivity",
    "href": "repo/micro-u/u6.html#directly-observable-and-testable-transitivity",
    "title": "Stochastic Choice",
    "section": "Directly Observable and Testable Transitivity",
    "text": "Directly Observable and Testable Transitivity\n\nIn deterministic models, transitivity is a single notion.\n\ne.g. in preference relations, transitivity is \\(x \\succ y\\) and \\(y \\succ z \\Rightarrow x \\succ z\\)\n\nIn random choice models, there are different strengths of transitivity.\n\nIf \\(\\rho(a,b) \\geq 1/2\\) and \\(\\rho(b,c) \\geq 1/2\\), then there exists\n\nweak transitivity if \\(\\rho(a,c) \\geq 1/2\\)\nmoderate transitivity if \\(\\rho(a,c) \\geq \\min\\{\\rho(a,b), \\rho(b,c)\\}\\)\n(He and Natenzon (2020))\nstrong transitivity if \\(\\rho(a,c) \\geq \\max\\{\\rho(a,b), \\rho(b,c)\\}\\)",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro I: Utility Theory",
      "Stochastic Choice"
    ]
  },
  {
    "objectID": "repo/ap/index.html",
    "href": "repo/ap/index.html",
    "title": "Asset Pricing Theory (PhD)",
    "section": "",
    "text": "Hi! This page hosts my notes on Asset Pricing Theory.\n\nConsumption-Based Pricing\n\nUsing stochastic discount factor (SDF) in a 2-period settings.\n\nConsumption-Based Pricing Extended\n\nExtending to broader time horizons and more economic settings.\n\nContingent Claims\n\nIntroducing the concept of contingent claims and connections to previous pricing models.\n\nFactor Models\nMacroeconomic Allocation\n\n\n\n\n Back to top",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Asset Pricing",
      "Asset Pricing Theory"
    ]
  },
  {
    "objectID": "repo/ap/a4.html",
    "href": "repo/ap/a4.html",
    "title": "Factor Models",
    "section": "",
    "text": "\\[\n\\def\\BB#1{{\\mathbb{#1}}}\n\\def\\BF#1{{\\mathbf{#1}}}\n\\def\\E{{\\mathbb{E}}}\n\\def\\R{{\\mathbb{R}}}\n\\]\n\nyedlu, Winter 2024\n\n\n\n Back to top",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Asset Pricing",
      "Asset Pricing Theory",
      "Factor Models"
    ]
  },
  {
    "objectID": "repo/ap/a3.html",
    "href": "repo/ap/a3.html",
    "title": "Contingent Claims and Market Completeness",
    "section": "",
    "text": "\\[\n\\def\\BB#1{{\\mathbb{#1}}}\n\\def\\BF#1{{\\mathbf{#1}}}\n\\def\\E{{\\mathbb{E}}}\n\\def\\R{{\\mathbb{R}}}\n\\]\nyedlu, Winter 2024",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Asset Pricing",
      "Asset Pricing Theory",
      "Contingent Claims"
    ]
  },
  {
    "objectID": "repo/ap/a3.html#contingent-claim-markets",
    "href": "repo/ap/a3.html#contingent-claim-markets",
    "title": "Contingent Claims and Market Completeness",
    "section": "Contingent Claim Markets",
    "text": "Contingent Claim Markets\n\nSettings\nWe have:\n\n\n\nNotation\nDescription\n\n\n\n\n\\(S\\)\nSet of states\n\n\n\\(x \\in \\BB{R}^S\\)\nPayoff vector for every possible states\n\n\n\n\n\nContingent Claim\nWe call a security contingent claim if it pays $1 in one particular future state \\(s^{*} \\in S\\) and zero in all other states.\nIn matrix notation, this is a standard-unit vector in \\(\\BB{R}^S\\). By definition, contingent claims are mutually independent and span the whole payoff space.\nWe use the notation \\(pc(s^*)\\) as the current price of the contingent claim for state \\(s^*\\).\n\n\nComplete Market through Contingent Claims\nIn a complete market, there exists a contingent claim for every possible state, either directly or through synthesizing.\nMarket completeness is an intriguing concept through this view: we are able to hedge any type of risk through contingent claims under market completeness.",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Asset Pricing",
      "Asset Pricing Theory",
      "Contingent Claims"
    ]
  },
  {
    "objectID": "repo/ap/a3.html#contingent-claim-pricing",
    "href": "repo/ap/a3.html#contingent-claim-pricing",
    "title": "Contingent Claims and Market Completeness",
    "section": "Contingent Claim Pricing",
    "text": "Contingent Claim Pricing\n\nHappy Meal Theorem\nIn a complete market, we can price an asset as:\n\\[\\begin{aligned}\n  p(x) &= \\sum_{s \\in S} pc(s) \\cdot x(s)\n\\end{aligned}\\]\nIntuition: the price of a payoff stream (which can be represent by linear combinations of contingent claims) should be the linear combination of contingent claim prices.\n\n\n\n\n\n\nNote\n\n\n\nWe will later discuss the assumption needed for this theorem to hold (namely law of one prices and/or arbitrage-free conditions).\n\n\n\n\nLinks to Consumption Pricing\nWe will derive and show how to link contingent claim pricing to the consumption pricing model.\nLet \\(\\pi(s)\\) be the probability that state \\(s \\in S\\) occurs. Then for the pricing equation:\n\\[\\begin{aligned}\n  p(x) &= \\sum_{s \\in S} \\pi(s) \\frac{pc(s)}{\\pi(s)} x(s)\n\\end{aligned}\\]\nWe define the state-dependent tochastic discount factor (SDF) in this model as:\n\\[\\begin{aligned}\n  m(s) := \\frac{pc(s)}{\\pi(s)}\n\\end{aligned}\\]\nIn this way, the contingent claim pricing equation becomes identical to the consumption pricing model:\n\\[\\begin{aligned}\n  p(x) &= \\sum_{s \\in S} \\pi(s) \\frac{pc(s)}{\\pi(s)} x(s) \\\\\n  &= \\sum_{s \\in S} \\pi(s) m(s) x(s) \\\\\n  &= \\E[mx]\n\\end{aligned}\\]\nIn a complete market, if SDF exists, then it is given by the set of contingent claim prices scaled by probability measures.\nWhat’s different now is that we do not assume investor-specific preferences (including utility functions and discount factors).",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Asset Pricing",
      "Asset Pricing Theory",
      "Contingent Claims"
    ]
  },
  {
    "objectID": "repo/ap/a3.html#risk-neutral-probabilities",
    "href": "repo/ap/a3.html#risk-neutral-probabilities",
    "title": "Contingent Claims and Market Completeness",
    "section": "Risk-Neutral Probabilities",
    "text": "Risk-Neutral Probabilities\n\nRisk-Free Rate\nWe have previously derived the risk-free rate using SDFs in consumption pricing. Now we try to derive it using contingent claim pricing. First, we write down the expected SDF under contingent claim pricing:\n\\[\\begin{aligned}\n  \\E[m] &= \\sum_{s \\in S} \\pi(s) m(s) \\\\\n  &= \\sum_{s \\in S} \\pi(s) \\frac{pc(s)}{\\pi(s)} \\\\\n  &= \\sum_{s \\in S} pc(s)\n\\end{aligned}\\]\nThen, using the finding from consumption pricing on risk-free rate, we have:\n\\[\\begin{aligned}\n  R^f &= \\frac{1}{\\E[m]} \\\\\n  &= \\frac{1}{\\sum_{s \\in S} pc(s)}\n\\end{aligned}\\]\n\n\nIntuition\nWe know from the definition of risk-free asset that its payoff vector would look like:\n\\[\\begin{aligned}\n  \\mathcal{A} &= (1, ..., 1)^{'} \\in \\R^n\n\\end{aligned}\\] given state set \\(S = (s_1, ..., s_n)\\).\nIf we were to assume complete markets, then the risk-free asset with the said payoff would have price:\n\\[\\begin{aligned}\n  p(\\mathcal{A}) &= \\sum_{i = 1}^{n} pc(s_i)\n\\end{aligned}\\] The return of investing this asset would be \\(1/\\sum_{i = 1}^{n} pc(s_i) = R^f\\).\n\n\nDefinition: Risk-Neutral Probabilities\nWe define:\n\\[\\begin{aligned}\n  \\pi^* (s) &:= R^f m(s) \\pi(s) \\\\\n  &= R^f pc(s) \\\\\n  &= \\frac{pc(s)}{\\sum_{s \\in S} pc(s)}\n\\end{aligned}\\] as the risk-neutral probability of state \\(s \\in S\\).\n\n\nRisk-Neutral Pricing\nUnder risk-neutral probabilities, we can derive further the contingent claim pricing model:\n\\[\\begin{aligned}\n  p(x) &= \\sum_{s \\in S} pc(s) x(s) \\\\\n  &= \\sum_{s \\in S} \\frac{\\pi^* (s)}{R^f} x(s) \\\\\n  &= \\frac{\\E^*[x]}{R^f}\n\\end{aligned}\\]\nWhere \\(\\E^*\\) is the expected payoff under risk-neutral probabilities.\n\n\nLinking Two Probabilities\nAlthough investors might have disagreements over the real probability, they must all agree on one set of risk-neutral probabilities. Rationale would be:\n\nall investors observe the same asset price;\nall investors infer and agree the same contingent claim prices\n\nThen, by the definition of risk-neutral probabilities:\n\\[\\begin{aligned}\n  \\pi^* (s) &= \\frac{pc(s)}{\\sum_{s \\in S} pc(s)}\n\\end{aligned}\\]\nall investors must all agree on the same \\(\\pi^* (s)\\).\n\n\nLinking Two Pricing Models\nComparing the consumption pricing model:\n\\[\\begin{aligned}\n  p &= \\E[mx] \\\\\n  &= \\sum_s \\pi(s) m(s) x(s) \\\\\n  &= \\frac{\\E[x]}{R^f} + \\sigma(m,x)\n\\end{aligned}\\]\nWith the contingent claim pricing model:\n\\[\\begin{aligned}\n  p &= \\sum_s pc(s) x(s) \\\\\n  &= \\frac{\\E^* [x]}{R^f}\n\\end{aligned}\\]\n\n\n\n\n\n\nNote\n\n\n\nWe can see that in addition to making risk adjustments to real-world probabilities, we can also discount the payoff directly as if we are in risk-neutral world. This makes sense intuitively if we consider:\n\nthe marginal investor in the economy can shift their risk preferences (hence hypothetically they can be risk-neutral)\nthe asset price has to be unanimously agreed upon (to reach an equilibrium) regardless of the marginal investor’s risk preference\nthus we can calculate directly the asset pricing as if everyone’s in the risk-neutral world",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Asset Pricing",
      "Asset Pricing Theory",
      "Contingent Claims"
    ]
  },
  {
    "objectID": "repo/sc/index.html",
    "href": "repo/sc/index.html",
    "title": "Stochastic Finance",
    "section": "",
    "text": "Hey! This page serves as a gateway of materials, mostly my notes and cheatsheets. I want to specifically acknowledge Prof. Lorenzo Naranjo for his intuitive lectures on Stochastic Foundations for Finance.\n\nDiscrete-Time Modeling Basis for discrete-time modeling.\n\n\n\n\n Back to top",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Asset Pricing",
      "Stochastic Finance"
    ]
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Open PDF"
  },
  {
    "objectID": "cv.html#basics",
    "href": "cv.html#basics",
    "title": "Curriculum Vitae",
    "section": "Basics",
    "text": "Basics\n\n\n\nName\n\n\nYanhe Eddie Lu\n\n\n\n\nLocation\n\n\nSt. Louis, MO\n\n\n\n\nU.S. Work Authorization\n\n\nSTEM-OPT (3 years)"
  },
  {
    "objectID": "cv.html#education",
    "href": "cv.html#education",
    "title": "Curriculum Vitae",
    "section": "Education",
    "text": "Education\n\nM.S. in Business Analytics (Financial Technology)\nOlin Business School, Washington University in St. Louis\n2023.08 - 2024.12\nGPA: 3.97/4.00\nHonors: Beta Gamma Sigma, Outstanding Student Award\nB.S. in International Economics & Financial Risk Management\nCentral University of Finance and Economics (CUFE)\n2019.08 - 2023.06\nGPA: 3.84/4.00"
  },
  {
    "objectID": "cv.html#research-experience",
    "href": "cv.html#research-experience",
    "title": "Curriculum Vitae",
    "section": "Research Experience",
    "text": "Research Experience\n\nEmpirical Corporate Finance\nResearch Assistant for Margarita Tsoutsoura, WashU Olin\n2024.05 - Present\nDistinguishing LLM-Generated Texts Using Linguistic Dimensions\nResearch Assistant for Gerald Onwujekwe, WashU Olin\n2024.01 - 2024.11\nEffects of Development Initiatives on Foreign Direct Investment\nSenior Thesis at CUFE\n2022.11 - 2023.05\nMechanisms of China’s National Carbon Market on Emissions\nResearch Analyst at International Institute of Green Finance, CUFE\n2022.02 - 2022.06\nEvaluating Corporate ESG Performance in the Diamond Industry\nResearch Analyst at International Institute of Green Finance, CUFE\n2022.02 - 2022.06\nModeling Sustainable Transformation of Global Food Systems\nContestant (Honorable Mentions) of Interdisciplinary Contest in Modeling\n2021.02"
  },
  {
    "objectID": "cv.html#professional-experience",
    "href": "cv.html#professional-experience",
    "title": "Curriculum Vitae",
    "section": "Professional Experience",
    "text": "Professional Experience\n\nFICC Product Specialist\nChina International Capital Corporation\n2023.03 - 2023.06\nCapital Markets Intern\nChina International Capital Corporation\n2022.06 - 2022.12\nInvestment Banking Intern\nChina Merchants Securities\n2022.02 - 2022.06\nWealth & Asset Management Consulting Assistant\nErnst & Young\n2021.12 - 2022.01"
  },
  {
    "objectID": "cv.html#teaching-experience",
    "href": "cv.html#teaching-experience",
    "title": "Curriculum Vitae",
    "section": "Teaching Experience",
    "text": "Teaching Experience\n\nTeaching Assistant\nOlin Business School, Washington University in St. Louis\n\nCapital Market and Financial Management\nUndergraduate, Spring 2024\nInstructor: Koray Sayili\nMachine Learning\nGraduate, Spring/Fall 2024\nInstructors: Durai Sundaramoorthi / Gerald Onwujekwe\nAdvanced Corporate Finance II - Financing\nGraduate, Fall 2024\nInstructor: Yaron Leitner\nFinancial Markets\nGraduate, Fall 2024\nInstructor: Yaron Leitner"
  },
  {
    "objectID": "cv.html#skills",
    "href": "cv.html#skills",
    "title": "Curriculum Vitae",
    "section": "Skills",
    "text": "Skills\n\nProgramming\nR, Python, Stata, MATLAB, SQL, SAS, AWS, Hive, LaTeX, Web Development\nLanguages\nMandarin: Native\nEnglish: Professional Fluency\nFrench: Conversational\nCommunication\nChinese National 2nd Prize in English Public Speaking\nUS Academic Decathlon Bronze Medal on Speaking"
  },
  {
    "objectID": "cv.html#coursework",
    "href": "cv.html#coursework",
    "title": "Curriculum Vitae",
    "section": "Coursework",
    "text": "Coursework\n\nFinance and Economics\nCorporate Finance Theory (PhD, Top of Class), Asset Pricing (PhD), Microeconomic Theory (PhD), Advanced Corporate Finance (Graduate, A+), Econometrics, Macroeconomics\nQuantitative Methods\nStochastic Processes, Probability and Statistics, Matrix Algebra, Calculus\nData and Programming Skills\nDatabase Design and SQL (A+), Big Data Analytics (A+), Text Mining (A+), Data Visualization (A+), Machine Learning, Python, R"
  },
  {
    "objectID": "cv.html#personal-information",
    "href": "cv.html#personal-information",
    "title": "Curriculum Vitae",
    "section": "Personal Information",
    "text": "Personal Information\n\nGuitarist for over 10 years\n\nArt and museum enthusiast\n\nPassionate home cook\n\nEnjoys cycling, hiking, and running"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About Me",
    "section": "",
    "text": "I am a graduate student at Washington University in St. Louis (WashU) Olin Business School, specializing in Analytics and Finance. My academic interest is in empirical corporate finance. I am currently seeking to pursue full-time research positions in empirical economic disciplines after my graduation in December 2024.\nThis website hosts my brief introduction of experiences in vitae section. You can also explore my repositories with concise notes/cheatsheets, projects, and coding samples.\n\n\nContact Information\nFeel free to reach out (click to copy):\nEmail:  eddie.lu@wustl.edu \nGitHub:  github.com/yedlu \nLinkedIn:  linkedin.com/in/yedlu \n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "repo/sc/s1.html",
    "href": "repo/sc/s1.html",
    "title": "Discrete-Time Finance",
    "section": "",
    "text": "\\[\n\\def\\BB#1{{\\mathbb{#1}}}\n\\def\\BF#1{{\\mathbf{#1}}}\n\\]\nyedlu, Winter 2024\nModeling evolutions of a variable is at the center of economic disciplines. We will first try to see tools we can use in discrete times and then push them forward in continuous times.",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Asset Pricing",
      "Stochastic Finance",
      "Discrete-Time Finance"
    ]
  },
  {
    "objectID": "repo/sc/s1.html#linear-difference-equations",
    "href": "repo/sc/s1.html#linear-difference-equations",
    "title": "Discrete-Time Finance",
    "section": "Linear Difference Equations",
    "text": "Linear Difference Equations\nConsider the following evolution:\n\\[\\begin{aligned}\n  y_t &= a + b y_{t-1}\n\\end{aligned}\\]\nwith \\(y_0\\) being a pre-determined constant.\nThen, we can iterate this over discrete times:\n\\[\\begin{aligned}\n  y_1 &= a + b y_0 \\\\\n  y_2 &= a + b y_1 = a + ba + b y_0 \\\\\n  y_3 &= a + b y_2 = a + ba + b^2 a + b^3 y_0 \\\\\n  & ... \\\\\n  y_t &= a (\\sum_{i=0}^{t-1} b^i) + b^t y_0\n\\end{aligned}\\]\nWe can further derive the geometric sum:\n\\[\\begin{aligned}\n  y_t &= a (\\sum_{i=0}^{t-1} b^i) + b^t y_0 \\\\\n  &= a (\\frac{1 - b^t}{1 - b}) + b^t y_0\n\\end{aligned}\\]\n\nConvergence\nThis condition\n\\[\\begin{aligned}\n  \\lim_{t \\to \\infty} \\frac{1 - b^t}{1 - b} = c, \\quad c \\in \\BB{R}\n\\end{aligned}\\]\nwould be true if\n\\[\\begin{aligned}\n  \\lim_{t \\to \\infty} b^t &= 0 \\\\\n  \\implies \\mid b \\mid &&lt; 1\n\\end{aligned}\\]\n\n\n\n\n\n\nTypes of Convergence\n\n\n\nIn financial models we would typically assume the convergence is monotonic:\n\\(b \\in (0,1)\\).\nNevertheless, alternating convergence might be useful in some cases:\n\\(b \\in (-1,0)\\).\n\n\n\n\nSolution\nAssuming convergence, the steady-state of \\(y_t\\) would then be:\n\\[\\begin{aligned}\n  \\overline{y} &= \\lim_{t \\to \\infty} = a (\\frac{1 - b^t}{1 - b}) + b^t y_0 \\\\\n  &= \\frac{a}{1-b}\n\\end{aligned}\\]\nAnother way to find the steady state is to assume existance of \\(\\overline{y}\\):\n\\[\\begin{aligned}\n  \\overline{y} &= a + b \\overline{y} \\\\\n  \\implies \\overline{y} &= \\frac{a}{1-b}\n\\end{aligned}\\]\n\n\nExponential Growth\nThe general solution\n\\[\\begin{aligned}\n  y_t &= \\overline{y} + b^t (y_0 - \\overline{y})\n\\end{aligned}\\] tells us a story. The discrete-time process begins at \\(y_0\\), converges to \\(\\overline{y}\\) in the end exponentially (\\(b^t\\)).",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Asset Pricing",
      "Stochastic Finance",
      "Discrete-Time Finance"
    ]
  },
  {
    "objectID": "repo/sc/s1.html#transversality-dividend-discount-revisited",
    "href": "repo/sc/s1.html#transversality-dividend-discount-revisited",
    "title": "Discrete-Time Finance",
    "section": "Transversality: Dividend Discount Revisited",
    "text": "Transversality: Dividend Discount Revisited\nWe know that the price of a stock can be denoted by the dividend discount model:\n\\[\\begin{aligned}\n  p_t &= \\frac{d_{t+1}}{1 + r} + \\frac{d_{t+2}}{(1 + r)^2} + ... + \\frac{d_{t+n}}{(1 + r)^n} + \\frac{p_{t+n}}{(1 + r)^n}\n\\end{aligned}\\]\nIf we were to allow the time period goes to infinity:\n\\[\\begin{aligned}\n  p_t &= \\sum_{i = 1}^{n} \\frac{d_{t+i}}{(1 + r)^i} + \\lim_{n \\to \\infty} \\frac{p_{t+n}}{(1 + r)^n}\n\\end{aligned}\\]\nWe can then see that the following assumption makes the price of the stock to be unique (transversality condition):\n\\[\\begin{aligned}\n  \\lim_{n \\to \\infty} \\frac{p_{t+n}}{(1 + r)^n} &= 0\n\\end{aligned}\\]\nIf this term explodes, we would not be able to obtain a unique price for this stock.\n\n\n\n\n\n\nTip\n\n\n\nThis would be an interesting concept in Asset Pricing called market completeness.",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Asset Pricing",
      "Stochastic Finance",
      "Discrete-Time Finance"
    ]
  },
  {
    "objectID": "repo/ap/a2.html",
    "href": "repo/ap/a2.html",
    "title": "Consumption-Based Pricing Extended",
    "section": "",
    "text": "\\[\n\\def\\BB#1{{\\mathbb{#1}}}\n\\def\\BF#1{{\\mathbf{#1}}}\n\\def\\E{{\\mathbb{E}}}\n\\]\nyedlu, Winter 2024",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Asset Pricing",
      "Asset Pricing Theory",
      "Consumption II"
    ]
  },
  {
    "objectID": "repo/ap/a2.html#consumption-pricing-characteristics",
    "href": "repo/ap/a2.html#consumption-pricing-characteristics",
    "title": "Consumption-Based Pricing Extended",
    "section": "Consumption Pricing Characteristics",
    "text": "Consumption Pricing Characteristics\n\nModel Assumption\nOne beauty of consumption-based pricing is that it requires very little assumption. One assumption that has to be satisfied is the investor is able to trade arbitrarily-small \\(\\xi\\) units of asset.\nHere’s a list of assumptions that the general consumption-based pricing do not assume:\n\n\n\n\n\n\n\nAssumption\nNotes\n\n\n\n\nComplete Markets\nMeasures individual-level willingness to pay, everyone can have different \\(p\\) under incomplete markets\n\n\nSpecific Return Distribution\nCan take any return distribution\n\n\nRepresentative/Marginal Investor\nThe SDF can be heterogenous to measure different types of investors\n\n\nSpecific Utility Functions\nCan take any form form of utility functions\n\n\nMarket Equilibrium\nWillingness to pay do not need market equilibrium to exist\n\n\n2-Period Model\nCan be expanded to multi-period form (later on)\n\n\nSpecific Beginning Endowment\nCan take any level of endowment\n\n\n\n\n\nReaching Equilibrium\nIn much rigor terms, \\(p\\) denotes individual investor’s willingness to pay to an asset. From above we know that the market does not have to be in eqilibrium for using the consumption-based pricing.\nWe will show now that, nevertheless, the market will finally be in congruent with the individual willingness to pay, reaching an equilibrium.\nTo begin with, purchasing \\(\\xi\\) units of asset in extra will increase the utility in the future by (discounted to today):\n\\[\\begin{aligned}\n  & \\beta \\E [u(c_{t+1} + \\xi x_{t+1}) - u(c_{t+1})] \\\\\n  = & \\beta \\E [u'(c_{t+1}) \\, \\xi x_{t+1} + ...]\n\\end{aligned}\\]\nFor an arbitrarily small \\(\\xi\\), only the first-order Taylor Expansion matters.\nSimilarly, purchasing \\(\\xi\\) units of asset will decrease today’s consumption. Using first-order Taylor expansion:\n\\[\\begin{aligned}\n  & u(c_t - \\xi v_t) \\\\\n  = & u'(c_t) \\xi v_t + ...\n\\end{aligned}\\]\nOptimality is reached if the investor is indifferent to buy additional \\(\\xi\\) units of asset. How does market reach equilibrium:\n\n\n\n\n\n\n\nScenario\nMechanism\n\n\n\n\n\\(v_t &gt; p_t\\)\nInvestor buys more asset because it is below valuation, then drives \\(c_t\\) down and \\(\\E [c_{t+1}]\\) up. Convexity drives the SDF down, hence \\(v_t\\) dropped till equilibrium.\n\n\n\\(v_t &lt; p_t\\)\nInvestor buys less asset because it is above valuation, driving \\(c_t\\) up and \\(\\E [c_{t+1}]\\) down. Convexity drives the SDF up, hence \\(v_t\\) increased till equilibrium.\n\n\n\\(v_t = p_t\\)\nIn equilibrium.\n\n\n\n\n\nInterconnected Random Variable\nFrom above we know that neither \\(p\\) and \\(c\\) are exogenous. They are linked through the consumption-based pricing model and interact each other. Specifically,\n\nknowing \\(\\E [mx]\\) yields the willingness to pay \\(p\\);\nknowing \\(p\\) yields investment decisions today.",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Asset Pricing",
      "Asset Pricing Theory",
      "Consumption II"
    ]
  },
  {
    "objectID": "repo/ap/a2.html#mean-variance-frontier-hansen-jagannathan-bounds",
    "href": "repo/ap/a2.html#mean-variance-frontier-hansen-jagannathan-bounds",
    "title": "Consumption-Based Pricing Extended",
    "section": "Mean-Variance Frontier (Hansen-Jagannathan Bounds)",
    "text": "Mean-Variance Frontier (Hansen-Jagannathan Bounds)\n\nDerivation\nGiven an asset’s riskiness, is there a reasonable bound for the return of the asset? We will try to derive the mean-variance frontier from our consumption pricing model.\n\\[\\begin{aligned}\n  1 &= \\E [mR^i] \\\\\n  &= \\E[m] \\E[R^i] + \\sigma(m, R^i) \\\\\n  &= \\frac{\\E[R^i]}{R^f} + \\rho (m, R^i) \\sigma(m) \\sigma(R^i)\n\\end{aligned}\\]\nRewriting the equation we would have:\n\\[\\begin{aligned}\n  \\E [R^i] - R^f &= - R^f \\rho (m, R^i) \\sigma(m) \\sigma(R^i) \\\\\n  R^f = \\frac{1}{\\E[m]} \\implies \\E [R^i] - R^f &= - \\rho (m, R^i) \\frac{\\sigma(m)}{\\E[m]} \\sigma(R^i)\n\\end{aligned}\\]\nBy Cauchy-Schwarz inequality:\n\\[\\begin{aligned}\n  \\mid \\E [R^i] - R^f \\mid &\\leq \\frac{\\sigma(m)}{\\E[m]} \\sigma(R^i)\n\\end{aligned}\\]\n\n\nGraphical Illustration\n\n\n\nSample Mean-Variance Frontier\n\n\nAssets on the upper bound:\n\\[\\begin{aligned}\n  \\E [R^i] &= R^f + \\frac{\\sigma(m)}{\\E[m]} \\sigma(R^i)\n\\end{aligned}\\] implies the correlation \\(\\rho(m, R^i) = -1\\). The asset return has perfect negative correlation with the SDF (hence perfect positive correlation with consumption). These types of asset bring higher volatility to consumption, thus investors would require a much higher excess return. One example would be stocks that goes high when market is bullist and plummets when market is bearish.\nThe lower bound, on the opposite,\n\\[\\begin{aligned}\n  \\E [R^i] &= R^f - \\frac{\\sigma(m)}{\\E[m]} \\sigma(R^i)\n\\end{aligned}\\] describes assets with high returns when consumptions are low. Consider insurances: normal investors would not require a high excess return on insurance products generally, as long as they can use these products to smoothen consumption levels across time and states.\n\n\nIllustration\nWe can compare assets within the wedge-shaped mean-variance frontier through two ways:\n\nHorizontally. If two assets (their corresponding points in the graph) lies under one horizontal line, then they have the same expected returns (\\(\\E[R^i]\\)). The asset on the left has lower overall risk (\\(\\sigma(R^i)\\)) which can be attributed to idiosyncratic risks.\n\nVertically. If two assets (their corresponding points in the graph) lies under one vertical line, then they have the same overall risk. The one that has a higher expected return (on the top) has a higher consumption-payoff correlation.\n\n\n\nSharpe Ratio\nThe Sharpe ratio measures the excess return (per unit of risk) and is defined as:\n\\[\\begin{aligned}\n  \\frac{\\E[R^i] - R^f}{\\sigma(R^i)}\n\\end{aligned}\\]\nWe can connect Sharpe ratio with the mean-variance frontier:\n\\[\\begin{aligned}\n  \\mid \\frac{\\E[R^i] - R^f}{\\sigma(R^i)} \\mid &\\leq \\frac{\\sigma(m)}{\\E[m]}\n\\end{aligned}\\] Intuition: the slope of the mean-variance frontier wedge is the maximum Sharpe ratio available.",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Asset Pricing",
      "Asset Pricing Theory",
      "Consumption II"
    ]
  },
  {
    "objectID": "repo/ap/a2.html#multi-period-pricing",
    "href": "repo/ap/a2.html#multi-period-pricing",
    "title": "Consumption-Based Pricing Extended",
    "section": "Multi-Period Pricing",
    "text": "Multi-Period Pricing\n\nSetting\nNow, the asset pays a stream of cash flows \\(\\{\\delta_{t+j}\\}\\) in the future. How should we price this multi-period asset?\n\n\nOptimization\nLet’s revisit the optimization problem:\n\\[\\begin{aligned}\n  \\max_{c_{t+j}} & \\quad \\BB{E}_t \\left[\\sum_{j = 0}^{\\infty} \\beta^j u(c_{t+j})\\right] \\\\\n  \\text{s.t.} & \\quad  c_t(\\xi) = e_t - p_t \\xi \\\\\n  & c_{t+j}(\\xi) = e_{t+j} + \\delta_{t+j} \\xi \\quad (j \\leq 1)\n\\end{aligned}\\]\nRearranging the objective function:\n\\[\\begin{aligned}\n  \\max_{\\xi} & \\quad \\left[u(e_t - p_t \\xi) + \\BB{E}_t \\left[ \\sum_{j = 1}^{\\infty} \\beta^j u(e_{t+j} + \\delta_{t+j} \\xi) \\right] \\right]\n\\end{aligned}\\]\nThe first-order condition (FOC) w.r.t \\(\\xi\\) of this objective function be:\n\\[\\begin{aligned}\n  - p_t u'(c_t) + \\E_t \\left[\\sum_{j = 1}^{\\infty} \\beta^j \\delta_{t+j} u'(c_{t+j}) \\right] = 0\n\\end{aligned}\\]\n\n\nSolution\nSolving for the price (willingness to pay):\n\\[\\begin{aligned}\n  p_t &= \\E_t \\left[\\sum_{j = 1}^{\\infty} \\beta^j \\frac{u'(c_{t+j})}{u'(c_t)} \\delta_{t+j} \\right]\n\\end{aligned}\\]\nWe define the multi-period stochastic discount factor (SDF) as:\n\\[\\begin{aligned}\n  m_{t+j} &:= \\beta^j \\frac{u'(c_{t+j})}{u'(c_t)} \\quad (j \\geq 1)\n\\end{aligned}\\]\n\n\nRisk-Adjusted Form\nAs in the two-period model, we can also rewrite prices as it is explicitly risk-adjusted:\n\\[\\begin{aligned}\n  p_t &= \\sum_{j = 1}^{\\infty} \\left[ \\frac{\\E_t [\\delta_{t+j}]}{R^f_{t, t+j}} + \\sigma(\\delta_{t+j}, m_{t, t+j}) \\right]\n\\end{aligned}\\]",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Asset Pricing",
      "Asset Pricing Theory",
      "Consumption II"
    ]
  },
  {
    "objectID": "repo/ap/a1.html",
    "href": "repo/ap/a1.html",
    "title": "Consumption-Based Pricing",
    "section": "",
    "text": "\\[\n\\def\\BB#1{{\\mathbb{#1}}}\n\\def\\BF#1{{\\mathbf{#1}}}\n\\]\nyedlu, Winter 2024",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Asset Pricing",
      "Asset Pricing Theory",
      "Consumption I"
    ]
  },
  {
    "objectID": "repo/ap/a1.html#riskiness-of-assets",
    "href": "repo/ap/a1.html#riskiness-of-assets",
    "title": "Consumption-Based Pricing",
    "section": "Riskiness of Assets",
    "text": "Riskiness of Assets\nWe’ve all heard of the term risk-free/risky assets, but how can we formally define the riskiness of assets?\nConsider the following simple state setting:\n\n\\(S = \\{s_1, s_2\\}\\) be the state space;\n\\(p_1, p_2 = 1 - p_1\\) be the probability of each state happening;\n\\(x_1, x_2\\) be the state-contingent payoff of the asset.\n\nWe will say an asset to be risk-free if the said asset pays the same payoff across every possible states in the state space:\n\\[\\begin{aligned}\n  x_1 = x_2\n\\end{aligned}\\]\nSimilarly, an asset is risky if the payoff is different across states:\n\\[\\begin{aligned}\n  x_1 \\neq x_2\n\\end{aligned}\\]",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Asset Pricing",
      "Asset Pricing Theory",
      "Consumption I"
    ]
  },
  {
    "objectID": "repo/ap/a1.html#pricing-through-consumption",
    "href": "repo/ap/a1.html#pricing-through-consumption",
    "title": "Consumption-Based Pricing",
    "section": "Pricing Through Consumption",
    "text": "Pricing Through Consumption\n\nSettings\nTo begin our analysis in the simpliest way possible, we assume that individual living in this economy only enjoys and values consumption over today (time \\(t\\)) and tomorrow (time \\(t+1\\)).\nHere are the notations useful in the model:\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\n\\(c_t\\)\nconsumption level at time \\(t\\)\n\n\n\\(u(\\cdot)\\)\nutility function over consumption level with \\(u' &gt; 0\\) (strictly increasing) and \\(u'' &lt; 0\\) (concave)\n\n\n\\(\\beta \\in (0, 1)\\)\ndiscount factor to future utility (investor impatience)\n\n\n\\(p_t\\)\nasset price (or more formally willingness to pay) at time \\(t\\)\n\n\n\\(x_{t+1}\\)\nasset payoff at time \\(t+1\\)\n\n\n\\(\\xi\\)\narbitratily-small unit of the asset an investor decides to buy\n\n\n\\(e_t\\)\nendowment level at time \\(t\\)\n\n\n\\(\\BB{E}_t\\)\nexpected utility conditional on all information available at time \\(t\\)\n\n\n\n\n\nThe Optimization Problem\nUnder this two-period setting, every individual is rational and wishes to maximize intertemporal utility through choosing consumption levels across the time horizon:\n\\[\\begin{aligned}\n  \\max_{c_t, c_{t+1}} \\quad u(c_t) + \\beta \\BB{E}_t [u(c_{t+1})]\n\\end{aligned}\\]\nWith the asset in the economy, we can further break down the consumption level. The optimization problem:\n\\[\\begin{aligned}\n  \\max_{c_t, c_{t+1}} & \\quad u(c_t(\\xi)) + \\beta \\BB{E}_t [u(c_{t+1}(\\xi))] \\\\\n  \\text{s.t.} \\quad c_t(\\xi) &= e_t - p_t \\xi \\\\\n  c_{t+1}(\\xi) &= e_{t+1} + x_{t+1} \\xi\n\\end{aligned}\\]\nnow have two budget constraints at both time periods.\n\n\nSolving the Optimization\nSimplify the objective function:\n\\[\\begin{aligned}\n  \\max_{\\xi} & \\quad u(e_t - p_t \\xi) + \\beta \\BB{E}_t [u(e_{t+1} + x_{t+1} \\xi)] \\\\\n\\end{aligned}\\]\nIts First-Order Condition (FOC) w.r.t. \\(\\xi\\) yields:\n\\[\\begin{aligned}\n  -p_t u'(e_t - p_t \\xi) + \\beta \\BB{E}_t [x_{t+1} u'(e_{t+1} + x_{t+1} \\xi)] = 0\n\\end{aligned}\\]\nClean this up and we would have:\n\\[\\begin{aligned}\n  \\beta \\BB{E}_t [x_{t+1} u'(c_{t+1})] = p_t u'(c_t)\n\\end{aligned}\\]\n\n\nIntuition of the FOC\nThe left-hand side: \\[\\begin{aligned}\n  \\beta \\BB{E}_t [x_{t+1} u'(c_{t+1})]\n\\end{aligned}\\] describes the future marginal utility gain of buying the asset, discounted to today’s term by \\(\\beta\\).\nThe right-hand side: \\[\\begin{aligned}\n  p_t u'(c_t)\n\\end{aligned}\\] describes today’s marginal disutility of buying the asset, as we are reducing consumption today.\nThe optimization amount of asset bought is then met when the marginal loss equals marginal gain.\n\n\nIntertemporal Asset Pricing Equation\nSolving for \\(p_t\\) of the FOC yields: \\[\\begin{aligned}\n  p_t = \\BB{E}_t [\\beta \\frac{u'(c_{t+1})}{u'(c_t)} x_{t+1}]\n\\end{aligned}\\] where future consumption level \\(c_{t+1}\\) and asset payoff \\(x_{t+1}\\) are all random variables (thus need to stay in the expectation).\nWe can see that the asset’s price (willingness to pay) is dependent to:\n\ninvestor-specific utility \\(u(\\cdot)\\);\nfuture states \\(\\BB{E}_t\\);\nendowment level \\(e\\);\ndiscount factor \\(\\beta\\);\nstate-contingent asset payoff \\(x_{t+1}\\).\n\n\n\nStochastic Discount Factor (SDF)\nWe denote the stochastic discount factor (SDF) as: \\[\\begin{aligned}\n  & m_{t+1} := \\frac{u'(c_{t+1})}{u'(c_t)} \\\\\n  \\implies & p_t = \\BB{E}_t [m_{t+1} x_{t+1}]\n\\end{aligned}\\]\nIntuitively, this factor serves as a risk-adjusted discount factor on individual level.",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Asset Pricing",
      "Asset Pricing Theory",
      "Consumption I"
    ]
  },
  {
    "objectID": "repo/ap/a1.html#applications",
    "href": "repo/ap/a1.html#applications",
    "title": "Consumption-Based Pricing",
    "section": "Applications",
    "text": "Applications\n\nDenoting Returns\nBy the definition of asset return, it is the dollar amount of payoff if we were to invest in one dollar of the asset. Transcribing this into our pricing equation:\n\\[\\begin{aligned}\n  1 &= \\BB{E}_t [m_{t+1} R_{t+1}]\n\\end{aligned}\\]\n\n\nRisk-Free Assets\nSuppose the risk-free rate is \\(R^f\\). Since this rate is not a random variable, we can further derive the pricing equation:\n\\[\\begin{aligned}\n  1 &= \\BB{E}_t [m_{t+1} R^f] = R^f \\BB{E}_t [m_{t+1}]\n\\end{aligned}\\] If we move back for one time period and use the law of iterated expectation:\n\\[\\begin{aligned}\n  1 &= R^f \\BB{E}_{t-1} [m_t] \\\\\n  \\implies \\BB{E}_{t-1} [m_t] &= \\frac{1}{R^f} \\\\\n  \\\\\n  \\BB{E} [m_t] &= \\BB{E}[\\BB{E}_{t-1} [m_t]] = \\BB{E}[\\frac{1}{R^f}] \\\\\n  &= \\frac{1}{R^f}\n\\end{aligned}\\] This links the risk-free rate to the stochastic discount factor!\n\n\nRisk-Free Rate Determinants\nSuppose our utility function: \\[\\begin{aligned}\n  u(c_t) &= \\frac{1}{1-\\gamma} c_t^{-\\gamma}\n\\end{aligned}\\] with \\(\\gamma &gt; 0\\).\nIf future consumption level is not random, then:\n\\[\\begin{aligned}\n  m_{t+1} &= \\left(\\frac{c_{t+1}}{c_t} \\right)^{-\\gamma} \\\\\n  \\implies m_t &= \\beta \\left(\\frac{c_{t+1}}{c_t} \\right)^{-\\gamma}\n\\end{aligned}\\]\nThen we can denote the risk-free rate as:\n\\[\\begin{aligned}\n  R^f &= \\frac{1}{\\beta} \\left(\\frac{c_{t+1}}{c_t} \\right)^{\\gamma}\n\\end{aligned}\\]\nThe following components can shift risk-free rate. Assume risk-free rate is increasing, this can be caused by:\n\n\n\n\n\n\n\n\nFactor\nDirection\nIntuition\n\n\n\n\n\\(\\beta\\)\n\\(\\downarrow\\)\nIf investors are more impatient, the risk-free rate must be high enough for them to give up liquidity today.\n\n\n\\(c_{t+1}/c_t\\)\n\\(\\uparrow\\)\nA high consumption growth in the future deters savings today. This also shifts \\(p_t\\) down as the asset must be more lucrative to attract investment.\n\n\n\\(\\gamma\\)\n\\(\\uparrow\\)\nA higher curvature will leads to a steeper decline to the first derivative. Then, investors are less prone to use asset to smooth consumption ceteris paribus.\n\n\n\n\n\nRisk Correction\nWe will derive and show that the stochastic discount factor is essentially a risk-corrected discount factor.\nBy the definition of covariance:\n\\[\\begin{aligned}\n  \\sigma_{m, x} &= \\BB{E}[mx] - \\BB{E}[m] \\BB{E} [x]\n\\end{aligned}\\]\nUsing it we derive:\n\\[\\begin{aligned}\n  p &= \\BB{E} [mx] = \\BB{E} [m] \\BB{E} [x] + \\sigma(m, x) \\\\\n  &= \\frac{\\BB{E}[x]}{R^f} + \\sigma(m, x)\n\\end{aligned}\\]\n\n\nCovariance of SDF and Payoff\nOn the covariance, assets whose payoff \\(x\\) is negatively correlated with the SDF (we will later show that together with convex utility, a higher SDF implies a smaller consumption growth) have a lower price.\nWe first further derive the risk-adjusted form of pricing formula:\n\\[\\begin{aligned}\n  p &= \\frac{\\BB{E}[x]}{R^f} + \\sigma_{m, x} \\\\\n  &= \\frac{\\BB{E}[x]}{R^f} + \\sigma_{\\beta \\frac{u'(c_{t+1})}{u'(c_t)}, x} \\\\\n  &= \\frac{\\BB{E}[x]}{R^f} + \\frac{\\beta \\sigma_{u'(c_{t+1}), x}}{u'(c_t)}\n\\end{aligned}\\]\nBy the assumption of the utility function, \\(u''&lt;0\\) holds. This implies that \\(u'(c_1) &gt; u'(c_2)\\) whenever \\(c_1 &lt; c_2\\).\nThen, the covariance \\(\\sigma_{u'(c_{t+1}), x}\\) is positive when the payoff of bad states (low consumption growth, higher \\(u'\\)) is high, vice versa.",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Asset Pricing",
      "Asset Pricing Theory",
      "Consumption I"
    ]
  },
  {
    "objectID": "repo/ap/a1.html#on-risk-corrections",
    "href": "repo/ap/a1.html#on-risk-corrections",
    "title": "Consumption-Based Pricing",
    "section": "On Risk Corrections",
    "text": "On Risk Corrections\n\nRisk-Neutral\nIf investors are risk-neutral in this economy, they only care about the expected consumption level. Hence, their utility function can be assumed to have a linear form:\n\\[\\begin{aligned}\n  u(c_t) &= a + b c_t\n\\end{aligned}\\]\nHence:\n\\[\\begin{aligned}\n  u'(c_t) &= b = u'(c_{t+1})\n\\end{aligned}\\]\nThen, with \\(m_t = \\beta\\) comes \\(\\sigma_{m, x} = 0\\): there are no risk adjustments to asset pricing:\n\\[\\begin{aligned}\n  p &= \\frac{\\BB{E}[x]}{R^f} + \\sigma_{m, x} \\\\\n  &= \\frac{\\BB{E}[x]}{R^f}\n\\end{aligned}\\]\n\n\nConstant Consumption\nIt is obvious that \\(u'(c_t) = u'(c_{t+1})\\) when \\(c_t = c_{t+1}\\).\n\n\nSystematic/Idiosyncratic Risks\nAssume we have an risky asset:\n\nidiosyncratic risks are payoff risks uncorrelated with market conditions (in here the SDF): \\(\\sigma_{m, x} = 0\\). These types of risks do not need to be adjusted by the market-wise SDF, as it is already implied by cash flow across states.\nsystematic risks are payoff risks correlated with market conditions (consumptions). Only systematic risks generate risk correction through SDF.\n\n\n\nExpected Return of Risky Assets\nFrom our results above, we have:\n\\[\\begin{aligned}\n  1 &= \\BB{E}[mR^i] \\\\\n  &= \\BB{E} [m] \\BB{E} [R^i] + \\sigma_{m, R^i} \\\\\n  &= \\frac{\\BB{E} [R^i]}{R^f} + \\sigma_{m, R^i} \\\\\n  \\\\\n  \\implies \\BB{E} [R^i] - R^f &= - R^f \\sigma_{m, R^i}\n\\end{aligned}\\] Further expanding \\(m\\) and \\(R^f\\) yields:\n\\[\\begin{aligned}\n  \\BB{E} [R^i] - R^f &= - \\left(\\BB{E} [m]\\right)^{-1} \\sigma_{m, R^i} \\\\\n  &= - \\left(\\BB{E} [\\beta \\frac{u'(c_{t+1})}{u'(c_t)}]\\right)^{-1} \\sigma_{\\beta \\frac{u'(c_{t+1})}{u'(c_t)}, R^i} \\\\\n  &= - \\frac{\\sigma_{u'(c_{t+1}), R^i}}{\\BB{E}[u'(c_{t+1})]}\n\\end{aligned}\\]\nIntuition:\n\nA higher excess return is required if \\(\\sigma_{u'(c_{t+1}), R^i}\\) is negative.\nBy convexity of utility, lower \\(u'\\) indicates higher consumption. This means that the asset has a higher return when consumption growth is high (good state) and vice versa. This makes consumption even more volatile and has to compensate investors.\nA lower excess return is required if \\(\\sigma_{u'(c_{t+1}), R^i}\\) is positive.\nConsider insurance products that pays when consumption growth is small (bad state) and do not pay vice versa. Since these products smooth consumption, we do not need additional incentive for investors to hold on to this asset.",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Asset Pricing",
      "Asset Pricing Theory",
      "Consumption I"
    ]
  },
  {
    "objectID": "repo/ap/a5.html",
    "href": "repo/ap/a5.html",
    "title": "Macroeconomic Allocation",
    "section": "",
    "text": "\\[\n\\def\\BB#1{{\\mathbb{#1}}}\n\\def\\BF#1{{\\mathbf{#1}}}\n\\def\\E{{\\mathbb{E}}}\n\\def\\R{{\\mathbb{R}}}\n\\]\nyedlu, Winter 2024",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Asset Pricing",
      "Asset Pricing Theory",
      "Macroeconomic Allocation"
    ]
  },
  {
    "objectID": "repo/ap/a5.html#settings",
    "href": "repo/ap/a5.html#settings",
    "title": "Macroeconomic Allocation",
    "section": "Settings",
    "text": "Settings\nWe are now standing in a macroeconomic view and try to price payoff streams (assets) in this way. Here’s some notations and settings used in this model.\n\nTime and States\n\n\n\n\n\n\n\nNotation\nDescription\n\n\n\n\n\\(t = 1, ...\\)\ndiscrete infinite time\n\n\n\\(s_t \\in S\\)\nstate realization at time \\(t\\)\n\n\n\\(s^t = (s_0, ..., s_t)\\)\nset of complete history realizations up until time \\(t\\)\n\n\n\\(\\pi(s^t)\\)\nunconditional probability of history \\(s^t\\) (often Markovian)\n\n\n\\(\\pi(s^t \\mid s^j)\\)\ntransition probability of history \\(s^t\\) conditioning on having observed history \\(s^j, j &lt; t\\)\n\n\n\n\n\nConsumers\n\n\n\n\n\n\n\nNotation\nDescription\n\n\n\n\n\\(i \\in I\\)\nset of consumers\n\n\n\\(y_t^i (s^t)\\)\nstochastic endowment at time \\(t\\) depending on history \\(s^t\\)\n\n\n\\(s^t\\)\nset of complete history can be publically observable\n\n\n\\(c^i = \\left\\{c_t^i (s^t) \\right\\}_{t=0}^{\\infty}\\)\nconsumption play of consumer \\(i\\) given the set of history realized \\(s^t\\)\n\n\n\\(U_i (c^i)\\)\nexpected utility function of consumer \\(i\\) (*)\n\n\n\\(u_i (c)\\)\nBernoulli index of utility function over consumption (we assume homogenous utility function across consumers) (**)\n\n\n\\(\\sum c_t^i \\leq \\sum y_t^i\\)\nat every time \\(t\\) and state \\(s^t\\) agents altogether can only consume what they earn\n\n\n\n(*) Utility function of consumer \\(i\\):\n\\[\\begin{aligned}\n  U_i (c^i) &= \\sum_{t = 0}^{\\infty} \\sum_{s^t} \\beta^t u_i\\left(c_t^i (s^t)\\right) \\pi_t(s^t) \\\\\n  &= \\E_0 \\left[\\sum_{t=0}^{\\infty}  \\beta^t u_i\\left(c_t^i (s^t)\\right) \\right]\n\\end{aligned}\\]\n(**) The Bernoulli index utility function over consumption is assumed to be:\n\nstrictly increasing (\\(u'&gt;0\\))\ntwice continuously differentiable and strictly concave (\\(u''&lt;0\\))\nsatisfies the Inada condition (\\(\\lim_{c \\to 0} u_i'(c) = + \\infty\\))",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Asset Pricing",
      "Asset Pricing Theory",
      "Macroeconomic Allocation"
    ]
  },
  {
    "objectID": "repo/ap/a5.html#social-planners-pareto-allocation",
    "href": "repo/ap/a5.html#social-planners-pareto-allocation",
    "title": "Macroeconomic Allocation",
    "section": "Social Planner’s Pareto Allocation",
    "text": "Social Planner’s Pareto Allocation\n\nEfficient Allocation\nWe need to find an efficient allocation, i.e. any reallocation of resources off this equilibrium will make at least one consumer worse off for any attempt to make another consumer better off.\n\n\nOptimization\nFor the social planner’s Pareto allocation, here are the elements for the solution:\n\nnon-negative (sometime regularized to \\((0,1)\\)) Pareto weights \\(\\lambda_i, i \\in I\\) to consumer’s utility\nPlanner chooses allocation \\(c^i\\) for each consumer to maximize collective welfare subject to feasibility constraint \\[\\begin{aligned}\n  \\max_{c^i} & \\sum_{i \\in I} \\lambda_i U_i(c^i) \\\\\n  \\text{s.t.} \\quad (\\forall t, s^t) \\sum_{i \\in I} c_t^i (s^t) & \\leq \\sum_{i \\in I} y_t^i (s^t)\n\\end{aligned}\\]\n\n\n\nSolution\nLet \\(\\theta_t(s^t) \\geq 0\\) be the Lagrange multiplier on the feasibility constraint at time \\(t\\) and history \\(s^t\\) (we need one multiplier for every time and history). Then, the Lagrangian of this problem equals:\n\\[\\begin{aligned}\n  L =& \\sum_{t} \\sum_{s^t} \\left[\\sum_{i} \\lambda_i \\beta^t u_i \\left(c_t^i(s^t) \\right) \\pi_t(s^t) \\right] \\\\\n  &+ \\sum_{t} \\sum_{s^t} \\left[\\theta_t(s^t) \\left[\\sum_{i} \\left(y_t^i (s^t) -  c_t^i (s^t) \\right) \\right] \\right]\n\\end{aligned}\\]\nThe first-order condition (FOC) w.r.t. \\(c_t^i (s^t)\\) for every agent, time, and history, yields:\n\\[\\begin{aligned}\n  \\beta^t u'_i \\left(c_t^i(s^t) \\right) \\pi_t(s^t) &= \\frac{1}{\\lambda_i} \\theta_t(s^t)\n\\end{aligned}\\]\nWe can divide consumer \\(i\\)’s FOC equation to consumer \\(1\\)’s FOC equation, leaving:\n\\[\\begin{aligned}\n  \\frac{u'_i \\left(c_t^i(s^t) \\right)}{u'_1 \\left(c_t^1(s^t) \\right)} &= \\frac{\\lambda_1}{\\lambda_i}\n\\end{aligned}\\]\nSolving for consumer \\(i\\)’s consumption, we have:\n\\[\\begin{aligned}\n  c_t^i(s^t) &= \\left(u_i' \\right)^{-1} \\left(\\frac{\\lambda_1}{\\lambda_i} u'_1 \\left(c_t^1(s^t) \\right)\\right)\n\\end{aligned}\\]\nWe can then use the feasibility constraint (binding) to solve for consumer \\(1\\)’s consumption:\n\\[\\begin{aligned}\n  \\sum_{i} \\left(u_i' \\right)^{-1} \\left(\\frac{\\lambda_1}{\\lambda_i} u'_1 \\left(c_t^1(s^t) \\right)\\right) &= \\sum_i y_t^i (s^t)\n\\end{aligned}\\]\n\n\nSame Aggregate Endowment\nIf the aggregated endowment are identical across two distinct histories:\n\\[\\begin{aligned}\n  \\sum_{i} y_t^i (s^{t, a}) &= \\sum_{i} y_t^i (s^{t, b})\n\\end{aligned}\\]\nthen also the allocation to every consumer must be the same at both histories:\n\\[\\begin{aligned}\n  c_t^i(s^{t, a}) &= \\left(u_i' \\right)^{-1} \\left(\\frac{\\lambda_1}{\\lambda_i} u'_1 \\left(c_t^1(s^t) \\right)\\right) = c_t^i(s^{t, b})\n\\end{aligned}\\]\nregardless of endowment contribution \\(y_t^i(s^{t, a})\\) and \\(y_t^i(s^{t, b})\\)!\n\n\nSummary\nFor given Pareto weights \\((\\lambda^i)_{i \\in I}\\), an efficient allocation is a function of the aggregated endowment and does neither depend separately on history \\(s^t\\) or individual contribution of the endowment \\(y_t^i(s^t)\\). It consists of a set of consumption allocation plan \\((c^1, ..., c^I)\\) that maximizes the aggregated social welfare determined by Pareto weights and utility functions.",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Asset Pricing",
      "Asset Pricing Theory",
      "Macroeconomic Allocation"
    ]
  },
  {
    "objectID": "repo/ap/a5.html#arrow-debreu-allocation",
    "href": "repo/ap/a5.html#arrow-debreu-allocation",
    "title": "Macroeconomic Allocation",
    "section": "Arrow-Debreu Allocation",
    "text": "Arrow-Debreu Allocation\n\nTime-Zero Trading\nNow, for this type of allocation (Arrow-Debreu), we assume\n\na complete set of time-history contingent claims \\(\\left\\{q_t^0(s^t) \\right\\}\\)\nall trade occurs only at time \\(0\\) after \\(s_0\\) is realized (superscript \\(0\\) denotes that all contingent claims are traded only at time \\(0\\))\nconsumers can trade contingent claims on time \\(t\\), history \\(s^t\\) at the price \\(q_t^0(s^t)\\)\nsince all trade occurs at time \\(0\\), each agent faces one single budget constraint:\n\\[\\begin{aligned}\n\\sum_t \\sum_{s^t} q_t^0(s^t) \\left(y_t^i (s^t) - c_t^i (s^t) \\right) \\geq 0\n\\end{aligned}\\]\nthe feasibility constraint of aggregated consumption at time \\(t\\) and history \\(s^t\\) still applies:\n\\[\\begin{aligned}\n\\sum_i c_t^i(s^t) \\leq \\sum_i y_t^i(s^t)\n\\end{aligned}\\]\n\n\n\nCompetitive Equilibrium\nUnlike social planner’s Pareto allocation, it takes two parts to solve the Arrow-Debreu allocation problem:\n\nfeasible allocation \\((c^1, .., c^I)\\)\nprice system (for contingent claims) \\(\\left\\{q_t^0 (s^t) \\right\\}_{t = 0}^{\\infty}\\)\n\nsuch that the allocation solves each consumer’s problem given the price system.\n\n\nOptimization\nWe then have the optimization problem formally defined:\n\\[\\begin{aligned}\n  \\max_{c^i} & \\sum_{t} \\sum_{s^t} \\beta^t u_i\\left(c_t^i (s^t) \\right) \\pi_t(s^t) = \\E_0 \\left[\\sum_{t} \\beta^t u_i(c_t^i) \\right] \\\\\n  \\\\\n  \\text{s.t.} \\quad & \\sum_t \\sum_{s^t} q_t^0(s^t) \\left(y_t^i (s^t) - c_t^i (s^t) \\right) \\geq 0 \\\\\n  & \\sum_i c_t^i(s^t) \\leq \\sum_i y_t^i(s^t)\n\\end{aligned}\\]\n\n\nSolution\nLet \\(\\mu_i \\leq 0\\) be the Lagrange multiplier to consumer \\(i\\)’s budget constraint. Then the Lagrangian for consumer \\(i\\) is:\n\\[\\begin{aligned}\n  \\mathcal{L}^i &= \\sum_{t} \\sum_{s^t} \\left[\\beta^t u_i\\left(c_t^i (s^t) \\right) \\pi_t(s^t) + \\mu_i q_t^0(s^t) \\left(y_t^i (s^t) - c_t^i (s^t) \\right) \\right]\n\\end{aligned}\\]\n\n\n\n\n\n\nTip\n\n\n\nWe would use the feasibility constraint later on in the solution.\n\n\nThe first-order condition (FOC) w.r.t. consumption \\(c_t^i (s^t)\\) for every \\(s^t\\) yields,\n\\[\\begin{aligned}\n  \\beta^t u_i'\\left(c_t^i (s^t) \\right) \\pi_t(s^t) = \\mu_i q_t^0(s^t)\n\\end{aligned}\\]\nThen, we can divide consumer \\(i\\)’s FOC equation to consumer \\(1\\)’s FOC equation (\\(i \\neq 1\\)): \\[\\begin{aligned}\n  \\frac{u_i'\\left(c_t^i(s^t)\\right)}{u_1'\\left(c_t^1(s^t)\\right)} &= \\frac{\\mu_i}{\\mu_1}\n\\end{aligned}\\]\nThen we can represent consumer \\(i\\)’s consumption as a function of consumer \\(1\\)’s consumption. For all other consumers and all possible histories:\n\\[\\begin{aligned}\n  c_t^i(s^t) &= \\left(u_i' \\right)^{-1} \\left(\\frac{\\mu_i}{\\mu_1} u'_1 \\left(c_t^1(s^t) \\right)\\right)\n\\end{aligned}\\]\nNow, we use the feasibility constraint:\n\\[\\begin{aligned}\n  \\sum_{i} \\left(u_i' \\right)^{-1} \\left(\\frac{\\mu_i}{\\mu_1} u'_1 \\left(c_t^1(s^t) \\right)\\right) &= \\sum_i y_t^i (s^t)\n\\end{aligned}\\]\nTherefore, the consumption for consumer \\(1\\) only depends on the aggregated endowment as well as the ratios of the Lagrange multiplier.\n\n\nSummary\nA competitive equilibrium allocation under Arrow-Debreu securities is a function of the aggregated endowment and does neither depend separately on history \\(s^t\\) or individual contribution of the endowment \\(y_t^i(s^t)\\).",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Asset Pricing",
      "Asset Pricing Theory",
      "Macroeconomic Allocation"
    ]
  },
  {
    "objectID": "repo/ap/a5.html#solution-characteristics",
    "href": "repo/ap/a5.html#solution-characteristics",
    "title": "Macroeconomic Allocation",
    "section": "Solution Characteristics",
    "text": "Solution Characteristics\n\nRegularization\nSince the price system denomination is arbitrary, tne technique that comes in handy is to regularize the time \\(0\\) price to one:\n\\[\\begin{aligned}\n  q_0^0 (s^t = (s_0)) &= \\frac{1}{\\mu_i} \\beta^t u_i'\\left(c_0^i(s^t=(s_0))\\right) \\pi_0(s_0) \\\\\n  &= \\frac{1}{\\mu_i} u_i'\\left(c_0^i(s^t=(s_0))\\right) \\\\\n  &= 1\n\\end{aligned}\\]\nThis immediately yields the Lagrange multiplier:\n\\[\\begin{aligned}\n  \\mu_i = u_i'\\left(c_0^i\\right)\n\\end{aligned}\\]\n\n\nNegishi Algorithm\nThough we must determine the price system and equilibrium allocation simultaneously, we can make use of the Negishi Algorithm and pinpoint our solution in a much more logical and simplier way. The algorithm, in a nutshell, does the following:\n\nFix a positive and arbitrary value for \\(\\mu_1\\). Then take uneducated guesses for all other \\(\\mu_i\\).\nSolve the allocation equation for \\(c^1\\). For all possible histories \\(s^t\\):\n\\[\\begin{aligned}\n\\sum_{i} \\left(u_i' \\right)^{-1} \\left(\\frac{\\mu_i}{\\mu_1} u'_1 \\left(c_t^1(s^t) \\right)\\right) &= \\sum_i y_t^i (s^t)\n\\end{aligned}\\]\nSolve all remaining \\(c^i\\) through: \\[\\begin{aligned}\nc_t^i(s^t) &= \\left(u_i' \\right)^{-1} \\left(\\frac{\\mu_i}{\\mu_1} u'_1 \\left(c_t^1(s^t) \\right)\\right)\n\\end{aligned}\\]\nThen solve the price system using the equilibrium allocation \\(c^i\\) for all \\(s^t\\) through: \\[\\begin{aligned}\n\\beta^t u_i'\\left(c_t^i (s^t) \\right) \\pi_t(s^t) = \\mu_i q_t^0(s^t)\n\\end{aligned}\\]\n\nFor all \\(i \\in I\\) check the budget constraint: \\[\\begin{aligned}\n\\sum_t \\sum_{s^t} q_t^0(s^t) \\left(y_t^i (s^t) - c_t^i (s^t) \\right) \\geq 0\n\\end{aligned}\\]\nRaise \\(\\mu_i\\) if cost of consumption exceeds endowment, vice versa.\nReiterate the algorithm until the budget constraint is binding for all consumer and histories.\n\n\n\nCRRA Utility Function\nIf we were to assume all consumers in this economy to have CRRA utility function: \\(u(c) = (1/1-\\gamma) c^{1-\\gamma}\\), then the optimality condition from the FOC implies:\n\\[\\begin{aligned}\n  \\frac{u_i'\\left(c_t^i(s^t)\\right)}{u_j'\\left(c_t^j(s^t)\\right)} &= \\frac{\\mu_i}{\\mu_j} \\\\\n  \\implies \\left[c_t^i(s^t)\\right]^{-\\gamma} &= \\left[c_t^j(s^t)\\right]^{-\\gamma} \\frac{\\mu_i}{\\mu_j} \\\\\n  \\implies c_t^i(s^t) &= c_t^j(s^t) \\left[\\frac{\\mu_i}{\\mu_j}\\right]^{-\\frac{1}[\\gamma]}\n\\end{aligned}\\]\nIt is surprising that under CRRA utility, agent \\(i\\) consumes the constant, history-independent fraction of agent \\(j\\)’s consumption! Nevertheless, we still need the feasibility constraint for every :\n\\[\\begin{aligned}\n  \\sum_i y_t^i(s^t) &= \\sum_i c_t^i(s^t) \\\\\n  &= c_t^i(s^t) \\left(1 + \\sum_{i} \\left[\\frac{\\mu_{-i}}{\\mu_i}\\right]^{-\\frac{1}{\\gamma}}\\right)\n\\end{aligned}\\]\nIf we denote \\(\\overline{y}_t(s^t) = \\sum_i y_t^i(s^t)\\), then:\n\\[\\begin{aligned}\n  c_t^1(s^t) &= \\overline{y}_t(s^t) \\left(1 + \\sum_{i \\in I \\setminus \\{1\\}} \\left[\\frac{\\mu_{i}}{\\mu_1}\\right]^{-\\frac{1}{\\gamma}}\\right)^{-1}\n\\end{aligned}\\]\nIf we denote:\n\\[\\begin{aligned}\n  Z &:= \\left(1 + \\sum_{i \\in I \\setminus \\{1\\}} \\left[\\frac{\\mu_{i}}{\\mu_1}\\right]^{-\\frac{1}{\\gamma}}\\right)^{-1}\n\\end{aligned}\\] then: \\[\\begin{aligned}\n  c_t^i(s^t) &= c_t^1(s^t) \\left[\\frac{\\mu_{i}}{\\mu_1}\\right]^{-\\frac{1}{\\gamma}} = \\left[\\frac{\\mu_{i}}{\\mu_1}\\right]^{-\\frac{1}{\\gamma}} Z \\, \\overline{y}_t(s^t) \\\\\n  &= \\alpha_i \\overline{y}_t(s^t)\n\\end{aligned}\\] where:\n\\[\\begin{aligned}\n  \\alpha_i &:= \\left[\\frac{\\mu_{i}}{\\mu_1}\\right]^{-\\frac{1}{\\gamma}} Z\n\\end{aligned}\\] is consumer \\(i\\)’s history indenpendent fixed consumption share of the aggregate endowment.\nFor the price system, we can derive further from the FOC condition:\n\\[\\begin{aligned}\n  q_t^0 (s^t) &= \\frac{1}{\\mu_i} \\beta^t \\pi_t(s^t) \\left[c_t^i(s^t)\\right]^{-\\gamma} \\\\\n  &= \\frac{1}{\\mu_i} \\beta^t \\pi_t(s^t) \\left[\\alpha_i \\overline{y}_t (s^t) \\right]^{-\\gamma}\n\\end{aligned}\\]\nAfter we normalize the time \\(0\\) state price:\n\\[\\begin{aligned}\n  q_0^0 (s^0) &= \\frac{1}{\\mu_i} \\left[\\alpha_i \\overline{y}_t (s^t) \\right]^{-\\gamma} = 1\n\\end{aligned}\\] we can have the price system for the competitive equilibrium.\nBut how to solve for \\(\\alpha\\)? We can use budget constraint for each consumer to solve for it: \\[\\begin{aligned}\n  0 &= \\sum_t \\sum_{s^t} q_t^0 (s^t) \\left[y_t^i (s^t) - c_t^i (s^t)\\right] \\\\\n  &= \\sum_t \\sum_{s^t} q_t^0 (s^t) \\left[y_t^i (s^t) - \\alpha_i \\overline{y}_t(s^t)\\right]\n\\end{aligned}\\] The budget constraint yields:\n\\[\\begin{aligned}\n  \\alpha_i &= \\frac{\\sum_t \\sum_{s^t} q_t^0 (s^t) y_t^i (s^t)}{\\sum_t \\sum_{s^t} q_t^0 (s^t) \\overline{y}_t(s^t)}\n\\end{aligned}\\]\n\n\nRiskless Aggregate Endowment\nWe will show subsequently that riskless aggregate endowment implies that consumption-per-consumer is time and history independent.\nStarting from the binding feasibility constraint:\n\\[\\begin{aligned}\n  \\sum_{i} \\left(u_i' \\right)^{-1} \\left(\\frac{\\mu_i}{\\mu_1} u'_1 \\left(c_t^1(s^t) \\right)\\right) = \\overline{y}_t (s^t)\n\\end{aligned}\\]\nThen since \\(\\frac{\\mu_i}{\\mu_1}\\) is time and history independent, a constant \\(\\overline{y}_t (s^t)\\) implies a constant \\(c_t^1(s^t)\\). Also from\n\\[\\begin{aligned}\n  c_t^i(s^t) &= \\left(u_i' \\right)^{-1} \\left(\\frac{\\mu_i}{\\mu_1} u'_1 \\left(c_t^1(s^t) \\right)\\right)\n\\end{aligned}\\]\nwe know that \\(c_t^i(s^t)\\) is also a constant for \\(i \\in I\\). Therefore, the equilibrium allocation satisfies:\n\\[\\begin{aligned}\n  c_t^i(s^t) &= \\overline{c}^i\n\\end{aligned}\\]\nfor all possible time and history.\nHow to solve the competitive equilibrium then? We can again start from the FOC:\n\\[\\begin{aligned}\n  \\beta^t u_i'\\left(c_t^i (s^t) \\right) \\pi_t(s^t) &= \\mu_i q_t^0(s^t) \\\\\n  \\implies q_t^0(s^t) &= \\frac{1}{\\mu_i} \\beta^t u_i'\\left(\\overline{c}^i\\right) \\pi_t(s^t)\n\\end{aligned}\\]\nAfter regularization of prices \\(\\mu_i = u_i'(\\overline{c}^i)\\), we can derive further using the budget constraint:\n\\[\\begin{aligned}\n  0 &= \\sum_t \\sum_{s^t} q_t^0(s^t) \\left(\\overline{c}^i - y_t^i(s^t)\\right) \\\\\n  &= \\sum_t \\sum_{s^t} \\frac{1}{\\mu_i} \\beta^t u_i'\\left(\\overline{c}^i\\right) \\pi_t(s^t) \\left(\\overline{c}^i - y_t^i(s^t)\\right)\n\\end{aligned}\\]\nSince \\(\\mu_i\\) and \\(u_i'\\left(\\overline{c}^i\\right)\\) are strictly positive, we can solve for \\(\\overline{c}^i\\):\n\\[\\begin{aligned}\n  \\overline{c}^i &= \\frac{\\sum_t \\sum_{s^t} \\beta^t \\pi_t(s^t) y_t^i(s^t)}{\\sum_t \\sum_{s^t} \\beta^t \\pi_t(s^t)} \\\\\n  &= \\frac{\\sum_t \\sum_{s^t} \\beta^t \\pi_t(s^t) y_t^i(s^t)}{\\sum_t \\beta^t \\sum_{s^t} \\pi_t(s^t)} \\\\\n  &= \\frac{\\sum_t \\sum_{s^t} \\beta^t \\pi_t(s^t) y_t^i(s^t)}{\\sum_t \\beta^t \\times 1} \\\\\n  &= (1-\\beta) \\left[\\sum_t \\sum_{s^t} \\beta^t \\pi_t(s^t) y_t^i(s^t)\\right] \\\\\n\\end{aligned}\\]\nIt is tedious but straightforward to verify that \\(\\sum_i \\overline{c}^i = \\overline{y}\\).",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Asset Pricing",
      "Asset Pricing Theory",
      "Macroeconomic Allocation"
    ]
  },
  {
    "objectID": "repo/ap/a5.html#linking-two-allocations-welfare-theorems",
    "href": "repo/ap/a5.html#linking-two-allocations-welfare-theorems",
    "title": "Macroeconomic Allocation",
    "section": "Linking Two Allocations: Welfare Theorems",
    "text": "Linking Two Allocations: Welfare Theorems\nThough we are assuming completely different settings in the two allocation models, we can easily link these two models using the following two Welfare Theorems.\n\nFirst Welfare Theorem\nA competitive equilibrium allocation is Pareto efficient.\n\n\n\n\n\n\nDefinition\n\n\n\nGiven a competitive equilibrium with equilibrium allocation \\((c^{1*}, ..., c^{I*})\\) and price system \\(\\left\\{q_t^0 (s^t)\\right\\}_{t=0}^{\\infty}\\), we can implement this as a Pareto equilibrium allocation with: \\[\\begin{aligned}\n  \\lambda_i := \\frac{1}{\\mu_i}, i \\in I\n\\end{aligned}\\]\n\n\n\n\nSecond Welfare Theorem\nThere exists a price system and an initial distribution of wealth that can support an efficient allocation as a competitive equilibrium allocation.\n\n\n\n\n\n\nDefinition\n\n\n\nGiven a Pareto equilibrium allocation with Pareto weights \\((\\lambda_i)_{i \\in I}\\) and equilibrium allocation \\((c^{1*}, ..., c^{I*})\\), we can implement this as an Arrow-Debreu competitive equilibrium allocation with: \\[\\begin{aligned}\n  q_t^0 (s^t) := \\theta_t(s^t) , \\quad \\forall s^t\n\\end{aligned}\\] and an allocation of endowment:\n\\[\\begin{aligned}\n  q_t^0 (s^t) y_t^i(s^t) = q_t^0 (s^t) c^{i*}\n\\end{aligned}\\]",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Asset Pricing",
      "Asset Pricing Theory",
      "Macroeconomic Allocation"
    ]
  },
  {
    "objectID": "repo/ap/a5.html#application",
    "href": "repo/ap/a5.html#application",
    "title": "Macroeconomic Allocation",
    "section": "Application",
    "text": "Application\n\nRedundant Asset Pricing\nAfter market completeness and no-arbitrage are assumed, we can price any redundant (i.e. each component has already been priced via state prices) asset with payoff \\(d_t(s^t)\\) using state prices (contingent claims):\n\\[\\begin{aligned}\n  p_0(s_0) &= \\sum_t \\sum_{s^t} q_t^0(s^t) d_t(s^t)\n\\end{aligned}\\] assuming state prices \\(q_t^0(s^t)\\) are already solved.",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Asset Pricing",
      "Asset Pricing Theory",
      "Macroeconomic Allocation"
    ]
  },
  {
    "objectID": "repo/ap/a5.html#sequential-trade",
    "href": "repo/ap/a5.html#sequential-trade",
    "title": "Macroeconomic Allocation",
    "section": "Sequential Trade",
    "text": "Sequential Trade\n\nSetting and Intuition\nIn the Arrow-Debreu setting, all trade takes place at time \\(0\\). We want to further relax this assumption by introducting trading opportunities across any sequence of time.\nIn sequential trading, there’s a sequence of markets that trade one-period-ahead state contingent claims.\n\n\n\n(Non) Financial Wealth\n\n\n\n\n\n\nDefinition: Non-Financial Wealth\n\n\n\nA consumer’s non-financial wealth is the continuation value of the consumer’s current and future endowment at time \\(t\\) and history \\(s^t\\):\n\\[\\begin{aligned}\n  \\sum_{\\tau = t}^{\\infty} \\sum_{s^{\\tau} \\mid s^t} q_{\\tau}^t y_{\\tau}^i (s^{\\tau})\n\\end{aligned}\\]\n\n\n\n\n\n\n\n\nDefinition: Financial Wealth\n\n\n\nAt time \\(t\\) and history \\(s^t\\), the financial wealth of consumer \\(i\\) is given by: \\[\\begin{aligned}\n\\Upsilon_t^i(s^t) := \\sum_{\\tau = t}^\\infty \\sum_{s^\\tau \\mid s^t} q_t^\\tau \\left(c_\\tau^i(s^\\tau) - y_\\tau^i(s^\\tau)\\right)\n\\end{aligned}\\] where:\n\n\\(q_t^\\tau\\): Arrow-Debreu state prices,\n\\(c_\\tau^i\\): consumption plan,\n\\(y_\\tau^i\\): endowment.\n\nThis wealth reflects the agent’s position in Arrow securities contingent on realized states.\n\n\nFinancial wealth at \\(t = 0\\) is always zero under Arrow-Debreu trade: \\[\\begin{aligned}\n\\Upsilon_0^i(s_0) = 0, \\quad \\forall i.\n\\end{aligned}\\] For \\(t &gt; 0\\), financial wealth can be positive or negative depending on the agent’s cross-insurance through Arrow securities.\n\n\n\n\n\n\nAggregation Constraint\n\n\n\nIn any competitive equilibrium, the sum of financial wealth across all agents equals zero: \\[\\begin{aligned}\n\\sum_{i=1}^I \\Upsilon_t^i(s^t) = 0, \\quad \\forall t, s^t.\n\\end{aligned}\\] Agents cross-insure across themselves and make sure that their claims on consumption level do not exceed the aggregated endowment at time \\(t\\) and history \\(s^t\\).\n\n\n\n\nNatural Debt Limits\nTo prevent Ponzi schemes, agents face a natural debt limit based on the value of their future endowments.\n\n\n\n\n\n\nDefinition: Natural Debt Limit\n\n\n\nThe natural debt limit \\(A_t^i(s^t)\\) for consumer \\(i\\) at time \\(t\\) and history \\(s^t\\) is: \\[\\begin{aligned}\nA_t^i(s^t) = \\sum_{\\tau = t}^\\infty \\sum_{s^\\tau \\mid s^t} q_t^\\tau y_\\tau^i(s^\\tau),\n\\end{aligned}\\] where \\(q_t^\\tau\\) represents the Arrow-Debreu price of future endowments. This is the maximum amount the agent can borrow assuming zero future consumption.\n\n\nBorrowing constraints ensure that agents cannot sell claims beyond their natural debt limit: \\[\\begin{aligned}\n-a_{t+1}^i(s^{t+1}, s^t) \\leq A_{t+1}^i(s^{t+1}).\n\\end{aligned}\\] For lending (\\(a_{t+1}^i &gt; 0\\)), this constraint is naturally satisfied, while for borrowing (\\(a_{t+1}^i &lt; 0\\)), it strictly limits over-leverage.\n\n\nConsumer’s Problem in Sequential Trade\nAgents aim to maximize their intertemporal utility subject to budget and borrowing constraints.\n\\[\\begin{aligned}\n  \\max_{c^i} \\quad & \\mathcal{L}_i = \\sum_{t=0}^\\infty \\sum_{s^t} \\beta^t u_i(c_t^i(s^t)) \\pi_t(s^t) \\\\\n  \\text{s.t.} \\quad &c_t^i(s^t) + \\sum_{s^{t+1} \\mid s^t} Q_t(s^{t+1} \\mid s^t) a_{t+1}^i(s^{t+1}, s^t) \\leq y_t^i(s^t) + a_t^i(s^t) \\quad \\text{(Budget)}\\\\\n  &-a_{t+1}^i(s^{t+1}, s^t) \\leq A_{t+1}^i(s^{t+1}), \\quad \\forall s^{t+1} \\quad \\text{(Borrowing)}\n\\end{aligned}\\]\n\n\nSolution\nThe consumer’s Lagrangian incorporates multipliers \\(\\eta_t^i(s^t)\\) for budget constraints and \\(\\nu_t^i(s^{t+1}, s^t)\\) for borrowing constraints: \\[\\begin{aligned}\n  \\mathcal{L}_i = & \\sum_{t=0}^\\infty \\sum_{s^t} \\Big[\\beta^t u_i(c_t^i(s^t)) \\pi_t(s^t) \\\\\n  &+ \\eta_t^i(s^t) \\left(y_t^i(s^t) + a_t^i(s^t) - c_t^i(s^t) - \\sum_{s^{t+1}} Q_t(s^{t+1} \\mid s^t) a_{t+1}^i(s^{t+1}, s^t)\\right) \\\\\n  &+ \\sum_{s^{t+1} \\mid s^t} \\nu_t^i(s^{t+1}, s^t) \\left(A_{t+1}^i(s^{t+1}) + a_{t+1}^i(s^{t+1}, s^t)\\right)\\Big].\n\\end{aligned}\\]\nTaking FOC:\n\nFor \\(c_t^i(s^t)\\): \\[\\begin{aligned}\n\\beta^t u'_i(c_t^i(s^t)) \\pi_t(s^t) = \\eta_t^i(s^t),\n\\end{aligned}\\]\nFor \\(a_{t+1}^i(s^{t+1}, s^t)\\): \\[\\begin{aligned}\n-\\eta_t^i(s^t) Q_t(s^{t+1} \\mid s^t) + \\nu_t^i(s^{t+1}, s^t) + \\eta_{t+1}^i(s^{t+1}) = 0.\n\\end{aligned}\\]\n\nIf borrowing limits are non-binding (\\(\\nu_t^i = 0\\)), the optimal pricing kernel is: \\[\\begin{aligned}\nQ_t(s^{t+1} \\mid s^t) = \\beta \\frac{u'_i(c_{t+1}^i(s^{t+1}))}{u'_i(c_t^i(s^t))} \\pi_t(s^{t+1} \\mid s^t).\n\\end{aligned}\\]\nKey Insight: Borrowing limits ensure feasibility without binding constraints under equilibrium, leveraging the Inada condition of utility.",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Asset Pricing",
      "Asset Pricing Theory",
      "Macroeconomic Allocation"
    ]
  },
  {
    "objectID": "repo/index.html",
    "href": "repo/index.html",
    "title": "Repositories",
    "section": "",
    "text": "Micro I: Utility Theories (PhD Level)\nMicro II: Game Theory (PhD Level)\n\n\n\n\n\nAsset Pricing Theory (PhD Level)\nStochastic Finance",
    "crumbs": [
      "me",
      "Repository"
    ]
  },
  {
    "objectID": "repo/index.html#class-notes",
    "href": "repo/index.html#class-notes",
    "title": "Repositories",
    "section": "",
    "text": "Micro I: Utility Theories (PhD Level)\nMicro II: Game Theory (PhD Level)\n\n\n\n\n\nAsset Pricing Theory (PhD Level)\nStochastic Finance",
    "crumbs": [
      "me",
      "Repository"
    ]
  },
  {
    "objectID": "repo/micro-u/u4.html",
    "href": "repo/micro-u/u4.html",
    "title": "Risk Aversion - Expected Utility over Money",
    "section": "",
    "text": "yedlu, Fall 2024",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro I: Utility Theory",
      "Risk Aversion"
    ]
  },
  {
    "objectID": "repo/micro-u/u4.html#notations",
    "href": "repo/micro-u/u4.html#notations",
    "title": "Risk Aversion - Expected Utility over Money",
    "section": "Notations",
    "text": "Notations\n\n\\(I = [\\underline{m}, \\overline{m}]\\) be the interval of monetary prizes in \\(\\mathbb{R}\\). Consider this as a continuous set of consequences.\n\\(p: I \\to [0,1]\\) be the simple lottery with finite support.\n\n\\(\\{m \\in I: p(m) &gt; 0\\}\\): only possible finite monetary prizes are considered.\n\n\\(\\mathcal{L}\\) be the set of simple lotteries over \\(I\\).\n\nThe preference relation on monetary simple lotteries is defined as \\(\\succsim \\subseteq \\mathcal{L} \\times \\mathcal{L}\\) such that \\(p \\succsim q \\Leftrightarrow (p,q) \\in \\succsim \\,\\, \\Leftrightarrow U(p) &gt; U(q)\\).\n\nvNM preferences on \\(\\mathcal{L}\\) are represented by an expected utility formed function:\n\n\\[U(p) = \\sum_{m \\in I} u(m) p(m)\\]",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro I: Utility Theory",
      "Risk Aversion"
    ]
  },
  {
    "objectID": "repo/micro-u/u4.html#evaluating-lotteries",
    "href": "repo/micro-u/u4.html#evaluating-lotteries",
    "title": "Risk Aversion - Expected Utility over Money",
    "section": "Evaluating Lotteries",
    "text": "Evaluating Lotteries\n\nFirst-Order Stochastic Dominance (FOSD)\nSettings: \\(F_p\\) is the cumulative probability distribution function (cdf) of lottery \\(p\\).\n\\(F_p(m) = \\sum_{\\alpha \\leq m} p(\\alpha)\\) is the probability that one can receive a monetary prize less than equal to \\(m\\).\nDefinition\nLottery \\(p\\) first-order stochastically dominates lottery \\(q\\) if\n\n\\(p \\neq q\\);\n\\(F_p(m) \\leq F_q(m)\\) for all \\(m \\in \\mathbb{R}\\).\n\nIntuition: lottery \\(p\\) have a lower chance receiving prizes lower than \\(m\\) compare to lottery \\(q\\). This implies that lottery \\(p\\) have a higher chance receiving prizes higher than \\(m\\) compare to lottery \\(q\\).\n\n\nSimple Improvements\nLottery \\(p\\) is a simple improvement over lottery \\(q\\) if\n\nthere exists \\(\\alpha \\in (0,1]\\);\n\\(m &gt; m'\\);\nthere exists \\(r \\in \\mathcal{L}\\)\n\nsuch that\n\\[\\begin{aligned}\n      p &= \\alpha \\delta_m + (1-\\alpha) r \\\\\n      q &= \\alpha \\delta_{m'} + (1-\\alpha) r \\\\\n\\end{aligned}\\]\nIntuition: we can consider both \\(p\\) and \\(q\\) as a mixture of a certain outcome monetary prize (\\(m\\) and \\(m'\\)), and a generic lottery \\(r\\).\nThis is a special case of first-order stochastic dominance.\nUtility representation:\n\\[\\begin{aligned}\n      U(p) = \\alpha u(m) + (1-\\alpha) u(r)p(r) &gt; \\alpha u(m') + (1-\\alpha) u(r)p(r) = U(q)\n\\end{aligned}\\]",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro I: Utility Theory",
      "Risk Aversion"
    ]
  },
  {
    "objectID": "repo/micro-u/u4.html#monotine-vnm-preferences",
    "href": "repo/micro-u/u4.html#monotine-vnm-preferences",
    "title": "Risk Aversion - Expected Utility over Money",
    "section": "Monotine vNM Preferences",
    "text": "Monotine vNM Preferences\nLet \\(\\succsim \\subseteq \\mathcal{L} \\times \\mathcal{L}\\) be a vNM prefernce. The following conditions are equivalent:\n\nIf \\(p\\) FOSD \\(q\\), then \\(p \\succ q\\).\nIf \\(p\\) is a simple improvement over \\(q\\), then \\(p \\succ q\\).\nEvery linear \\(U: \\mathcal{L} \\to \\mathbb{R}\\) representing \\(\\succsim\\) has a strictly increasing Bernoulli index u.\n\nWhen \\(\\succsim\\) satisfies three conditions above, we call it a monotone vNM preference.",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro I: Utility Theory",
      "Risk Aversion"
    ]
  },
  {
    "objectID": "repo/micro-u/u4.html#certainty-equivalent",
    "href": "repo/micro-u/u4.html#certainty-equivalent",
    "title": "Risk Aversion - Expected Utility over Money",
    "section": "Certainty Equivalent",
    "text": "Certainty Equivalent\nLet \\(\\succsim \\subseteq \\mathcal{L} \\times \\mathcal{L}\\) be a vNM prefernce represented by an expected utility function with a continuous index \\(u: I \\to \\mathbb{R}\\). Then \\(C: \\mathcal{L} \\to \\mathbb{R}\\) given by \\(\\delta_{C(p)} \\sim p\\) is a well-defined function. \\(C(p)\\) is the certainty equivalent of lottery \\(p\\).",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro I: Utility Theory",
      "Risk Aversion"
    ]
  },
  {
    "objectID": "repo/micro-u/u4.html#risk-aversion",
    "href": "repo/micro-u/u4.html#risk-aversion",
    "title": "Risk Aversion - Expected Utility over Money",
    "section": "Risk Aversion",
    "text": "Risk Aversion\n\nRisk Averse Preferences\nLet \\(\\overline{p} = \\sum_{x \\in I} p(x) x\\) be the expected payoff of lottery. The preference \\(\\succsim\\) is risk averse when \\(\\delta_{\\overline{p}} \\succsim p\\).\n\n\nSimple Mean Preserving Spread\n\\(q\\) is a simple mean preserving spread of \\(p\\) when for some \\(\\alpha \\in (0,1]\\), some \\(r, r' \\in \\mathcal{L}\\) and \\(\\overline{r'} = m\\).\n\\[\\begin{aligned}\n      p & = \\alpha \\delta_{m} + (1-\\alpha) r \\\\\n      q & = \\alpha r' + (1-\\alpha) r\n\\end{aligned}\\]\nIntuition: \\(p\\) and \\(q\\) yields the same expected payoff, but \\(q\\) has higher variance than of \\(p\\).\n\n\nRisk Aversion Theorems\nLet \\(\\succsim\\) be a monotone vNM preference. The following are equivalent:\n\n\\(\\succsim\\) is risk averse;\nIf \\(q\\) is a mean preserving spread over \\(p\\) then \\(p \\succ q\\);\nEvery linear \\(U: \\mathcal{L} \\to \\mathbb{R}\\) representing \\(\\succsim\\) has a concave Bernoulli function.\n\nIf \\(u\\) is a concave bernoulli function, we would have:\n\\[1/2 u(a) + 1/2 u (b) \\leq u(a/2 + b/2)\\]\n\n\nLevels of Risk Aversion\n\\(\\succsim\\) is more risk averse than \\(\\succsim'\\) when \\(\\delta_m \\succsim' p\\) implies \\(\\delta_m \\succsim p\\).\nSuppose \\(u, v\\) are continuous Bernoulli indices for monotone vNM preferences \\(\\succsim\\) and \\(\\succsim'\\). Then the following conditions are equivalent:\n\n\\(\\succsim\\) is more risk averse than \\(\\succsim'\\)\nthere exists a concave, strictly increasing function \\(f: u(\\mathbb{R}) \\to \\mathbb{R}\\) such that \\(v(m) = f \\circ u(m) = f(u(m))\\).",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro I: Utility Theory",
      "Risk Aversion"
    ]
  },
  {
    "objectID": "repo/micro-u/u1.html",
    "href": "repo/micro-u/u1.html",
    "title": "Choices/Preference/Utility over Finite Outcomes",
    "section": "",
    "text": "* in conjunction with §1 of Microeconomics Foundation I (Kreps, 2013)\nyedlu, Fall 2024",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro I: Utility Theory",
      "Finite Outcomes"
    ]
  },
  {
    "objectID": "repo/micro-u/u1.html#key-concepts-overview",
    "href": "repo/micro-u/u1.html#key-concepts-overview",
    "title": "Choices/Preference/Utility over Finite Outcomes",
    "section": "Key Concepts Overview",
    "text": "Key Concepts Overview\n\n1. Choices\nChoices are observable actions taken when confronted with alternatives. Economists model choices using the following notations:\n\n\n\n\n\n\n\n\nNotation\nDefinition\nExample\n\n\n\n\n\\(X\\)\nFinite set of alternatives\nColleges someone can apply: \\(X = \\{a,b,c\\}\\)\n\n\n\\(P(X)\\)\nAll non-empty subsets of \\(X\\)\n\\[ P(X) = \\{\\{a\\}, \\{b\\}, \\{c\\}, \\{a,b\\}, \\{a,c\\}, \\{b,c\\}, \\{a,b,c\\}\\} \\]\n\n\n\\(B \\subseteq P(X)\\)\nSet of feasible choice menus\n\\(B = \\{\\{a\\}, \\{a,b\\}, \\{a,b,c\\}\\}\\)\n\n\n\\(c: B \\to P(X)\\)\nChoice function: \\(c(A) \\subset A\\)\n\\(c(\\{a,b,c\\}) = \\{a,b\\}\\)\n\n\n\n\n\n2. Preferences\nPreferences reflect internal evaluations of choices, modeled abstractly:\n\n\n\n\n\n\n\n\nNotation\nDefinition\nExample\n\n\n\n\n\\(X\\)\nSet of alternatives\n\\(X = \\{a,b,c\\}\\)\n\n\n\\(X \\times X\\)\nCartesian product: pairs of alternatives\n\\((a,b), (b,c), \\dots\\)\n\n\n\\(R \\subseteq X \\times X\\)\nBinary relation: \\((a,b) \\in R \\iff a \\succsim b\\)\nPreferences: \\(a \\succsim b, b \\succsim c\\)\n\n\n\n\nProperties of \\(R\\):\n\nComplete: For all \\(x, y \\in X\\), \\(x \\succsim y\\) or \\(y \\succsim x\\).\nTransitive: \\(x \\succsim y\\) and \\(y \\succsim z \\implies x \\succsim z\\).\nRational: \\(R\\) is complete and transitive.\n\n\n\n\n3. Choices from Preferences\nA rational binary relation \\(R\\) generates a choice function \\(c_R\\):\n\\[\nc_R(A) := \\{x \\in A \\mid (\\forall y \\in A) \\, (x,y) \\in R\\}\n\\]\n\n\nProofs\n\nProposition 1: If \\(R\\) is rational, then \\(c_R\\) is a choice function.\n\n\nProof (Click to Expand)\n\nBy induction. Need to show that \\(c_R (A) \\neq \\emptyset\\) for all \\(A \\subseteq X\\).\n\nBase Case (\\(|A| = 1\\)):\nLet \\(A = \\{x\\}\\). A complete \\(R\\) implies that \\((x,x) \\in R\\), which in turn implies that \\(c_R (A) = \\{x\\} \\neq \\emptyset\\).\nInductive Step (\\(|A| = n + 1\\)):\nAssume true for \\(|A| = n\\). Pick any \\(x \\in A\\). By assumption, \\(c_R (A \\setminus \\{x\\}) \\neq \\emptyset\\).\n\nBy definition, there exists \\(y \\in A \\setminus \\{x\\}\\) such that \\((y,z) \\in R\\) for all \\(z \\in A \\setminus \\{x\\}\\).\nSince \\(R\\) is complete, either \\((x,y) \\in R\\) or \\((y,x) \\in R\\).\n\nIf \\((x,y) \\in R\\), then transitivity implies \\((x,z) \\in R\\) for all \\(z \\in A\\), so \\(x \\in c_R(A)\\).\nIf \\((y,x) \\in R\\), then \\(y \\in c_R(A)\\).\n\n\n\nThus, \\(c_R (A) \\neq \\emptyset\\) for all \\(A \\subseteq X\\).\n\\(\\blacksquare\\)\n\n\n\nProposition 2: If \\(c\\) satisfies WARP, then \\(R_c\\) is a rational preference relation.\n\n\nProof (Click to Expand)\n\n\nCompleteness:\nTake any \\(x, y \\in X\\).\n\nIf \\((x,y) \\notin R_c\\), then \\(x \\notin c(\\{x,y\\})\\).\n\nBy definition, \\(y \\in c(\\{x,y\\})\\), so \\((y,x) \\in R_c\\).\nTherefore, \\(R_c\\) is complete.\n\nTransitivity:\nSuppose \\((x,y) \\in R_c\\) and \\((y,z) \\in R_c\\).\n\nThis implies \\(x \\in c(\\{x,y\\})\\) and \\(y \\in c(\\{y,z\\})\\).\n\nAssume \\((x,z) \\notin R_c\\). Then \\(z \\in c(\\{x,z\\})\\) contradicts WARP.\nHence, \\((x,z) \\in R_c\\), and \\(R_c\\) is transitive.\n\\(\\blacksquare\\)\n\n\n\n\n\n\n4. Preferences Revealed by Choices\nRevealed preference relation \\(R_c\\):\n\\[\nR_c := \\{(x,y) \\in X \\times X \\mid x \\in c(\\{x,y\\})\\}\n\\]\n\nWeak Axiom of Revealed Preferences (WARP):\nIf \\(x, y \\in A \\cap B\\), \\(x \\in c(A)\\), and \\(y \\in c(B)\\), then \\(x \\in c(B)\\).",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro I: Utility Theory",
      "Finite Outcomes"
    ]
  },
  {
    "objectID": "repo/micro-u/index.html",
    "href": "repo/micro-u/index.html",
    "title": "Choices, Preferences, and Utility Theories",
    "section": "",
    "text": "Hi there and welcome! You can navigate yourself through one of the following topics:\n\nChoices/Preference/Utility over Finite Outcomes\n\nDefinition and properties of choices, preference relations, and representing utility functions.\n\nChoices/Preference/Utility over Infinite Outcomes\n\nBring the concepts to infinite set of consequences.\n\nvon Neumann-Morgenstern Expected Utility\n\nExplore lotteries and expected utility theory.\n\nRisk Aversion\n\nExamining risk aversion and its role in rational decision-making.\n\nAfriat’s Theorem\n\nAn introduction to Afriat’s theorem and its implications.\n\nStochastic Choice\n\nThe theory behind stochastic choices.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro I: Utility Theory"
    ]
  },
  {
    "objectID": "repo/micro-g/g1.html",
    "href": "repo/micro-g/g1.html",
    "title": "Normal-Form Games",
    "section": "",
    "text": "\\[\n\\def\\BB#1{{\\mathbb{#1}}}\n\\def\\BF#1{{\\mathbf{#1}}}\n\\]\nyedlu, Winter 2024",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro II: Game Theory",
      "Normal-Form Games"
    ]
  },
  {
    "objectID": "repo/micro-g/g1.html#game-theory-an-introduction",
    "href": "repo/micro-g/g1.html#game-theory-an-introduction",
    "title": "Normal-Form Games",
    "section": "Game Theory: An Introduction",
    "text": "Game Theory: An Introduction\nGame theory can be defined as the study of mathematical models of conflict and cooperation between decision-makers who are\n\nintelligent: players inside the game are aware of their situation just like the researchers studying the game\n\nrational: maximizing some preference or utility functions\n\nIt is the tool to model situations in which decision-makers interact and influence one another’s welfare.\nThe Expected Utility Theory (with vNM theorem) would come in handy when dealing with games.\n\nGames in Normal-Form\nThis is a model of interactive decision-making in which each decision-maker chooses their plan of action once and for all, and these choices are made simultaneously.\nThree key components of normal-form games:\n\nThe finite set of players: \\(N = \\{1, 2, ..., n\\}\\)\nFor each player the nonempty set of actions: \\(S_i\\) with \\(i \\in N\\)\nFor each player the preference relation \\(R_i\\) on lotteries: \\(S = S_1 \\times S_2 \\times ... \\times S_n\\)\n\nAll players in normal-form games are expected utility maximizers. A notation for the game, in expected utility form, would be: \\[\\begin{align}\n    G = (N, (S_i: i \\in N), (u_i: i \\in N))\n\\end{align}\\]\nSometimes consequences \\(C\\) are mentioned explicitly.\n\n\\(R_i^*\\) be a preference relation over \\(C\\)\n\\(g: S \\to C\\) maps actions to consequences\n\\(s R_i s'\\) when \\(g(s) R_i^* g(s')\\)\n\nGame theory cannot say about what the preference relation \\(R_i\\) should be. Rather, it has a lot to say about how a game will be played/should be played conditioning on the preference relation.",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro II: Game Theory",
      "Normal-Form Games"
    ]
  },
  {
    "objectID": "repo/micro-g/g1.html#example-ben-polaks-grading-game",
    "href": "repo/micro-g/g1.html#example-ben-polaks-grading-game",
    "title": "Normal-Form Games",
    "section": "Example: Ben Polak’s Grading Game",
    "text": "Example: Ben Polak’s Grading Game\nThis game provides an example of how to understand the payoff matrix. It also shows how to spot strictly dominated strategies and why we should never play them in a normal-form game.\n\n\nClick to Explore\n\nIn standard notations, Ben Polak’s Grading Game can be denoted as:\n\n\\(N \\ \\{1,2\\}\\) be the set of players\n\\(S_1 = S_2 = \\{\\alpha, \\beta\\}\\) be the set of actions\n\\(S = S_1 \\times S_2 = \\{(\\alpha, \\alpha), (\\alpha, \\beta), (\\beta, \\alpha), (\\beta, \\beta)\\}\\) be the cartesian product of action sets. This is the set of all possible results.\n\\(u_i: S \\to \\mathbb{R}, i \\in N\\) be the Bernoulli index. Different players might have different Bernoulli indices.\n\nThe outcome matrix is as follows:\n\n\n\n\n\\(\\alpha\\)\n\\(\\beta\\)\n\n\n\n\n\\(\\alpha\\)\nB-, B-\nA, C\n\n\n\\(\\beta\\)\nC, A\nB+, B+\n\n\n\nLet’s say, for example, that Bernoulli payoff functions for two types of players in the crowd are as follows:\n\n\n\nTypes\n\\((A, C)\\)\n\\((B+, B+)\\)\n\\((B-, B-)\\)\n\\((C, A)\\)\n\n\n\n\nSelfish\n3\n2\n1\n0\n\n\nIndignant Angel\n0\n2\n1\n-1\n\n\n\nThen we can take a look at outcomes under the scenarios below.\n\nSelfish vs. Selfish\n\n\n\n\n\\(\\alpha\\)\n\\(\\beta\\)\n\n\n\n\n\\(\\alpha\\)\n1, 1\n3, 0\n\n\n\\(\\beta\\)\n0, 3\n2, 2\n\n\n\nIt is easy to show that both row and column players have a strictly dominated action: \\[\\begin{aligned}\n    u(\\alpha, \\alpha) & &gt; u(\\beta, \\alpha) \\\\\n    u(\\alpha, \\beta) & &gt; u(\\beta, \\beta)\n\\end{aligned}\\]\n\n\nIndignant Angel vs. Indignant Angel\n\n\n\n\n\\(\\alpha\\)\n\\(\\beta\\)\n\n\n\n\n\\(\\alpha\\)\n1, 1\n0, -1\n\n\n\\(\\beta\\)\n-1, 0\n2, 2\n\n\n\nNo strictly dominated actions exist in this case. However, it is interesting to notice that both (\\(\\alpha, \\alpha\\)) and (\\(\\beta, \\beta\\)) are locally optimal answers.\n\n\nSelfish vs. Indignant Angel\n\n\n\n\n\\(\\alpha\\)\n\\(\\beta\\)\n\n\n\n\n\\(\\alpha\\)\n1, 1\n3, -1\n\n\n\\(\\beta\\)\n0, 3\n2, 2\n\n\n\nIt is easy to show that row player have a strictly dominated action: \\[\\begin{aligned}\n    u(\\alpha, \\alpha) & &gt; u(\\beta, \\alpha) \\\\\n    u(\\alpha, \\beta) & &gt; u(\\beta, \\beta)\n\\end{aligned}\\]\nSince our agents are intelligent, the column player knows that the row player is guaranteed to play \\(\\alpha\\). Conditioning on this information, the column player would also play \\(\\alpha\\).",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro II: Game Theory",
      "Normal-Form Games"
    ]
  },
  {
    "objectID": "repo/micro-g/g1.html#strictly-dominated-actions",
    "href": "repo/micro-g/g1.html#strictly-dominated-actions",
    "title": "Normal-Form Games",
    "section": "Strictly Dominated Actions",
    "text": "Strictly Dominated Actions\nIn the normal-form game \\(G\\), we say that action \\(s_i^{'} \\in S_1\\) is strictly dominated by action \\(s_i^{''} \\in S_1\\) if, for every \\(s_{-i} \\in S_1 \\times ... \\times S_{i-1} \\times S_{i+1} \\times ... \\times S_n\\): \\[\\begin{aligned}\n    u(s_i^{''}, s_{-i}) &gt; u(s_i^{'}, s_{-i})\n\\end{aligned}\\]\n\nIterated Elimination of Dominated Actions (IEDA)\nIntuition: eliminate dominated actions round-by-round until no actions dominates other actions.\nFormal definition: let rounds of elimination be \\(t = 1, 2, ..., T\\).\nFor every player \\(i\\),\n\nstart with all actions \\(S_i^1 = S_i\\)\n\neliminate some actions at each round \\(S_i^1 \\supset S_i^2 \\supset ... \\supset S_i^T\\)\n\nOnly strictly dominated actions are eliminated: if \\(s_i^{''} \\in S_i^T \\setminus S_i^{T+1}\\) then \\(s_i^{''}\\) is strictly dominated by some \\(s_i^{'} \\in S_i^{T+1}\\).\nNobody is left with any strictly actions at the end. The set of consequenses in the end would be \\(S_1^T \\times ... \\times S_n^T\\).",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro II: Game Theory",
      "Normal-Form Games"
    ]
  },
  {
    "objectID": "repo/micro-g/g1.html#nash-equilibrium-and-mixed-actions",
    "href": "repo/micro-g/g1.html#nash-equilibrium-and-mixed-actions",
    "title": "Normal-Form Games",
    "section": "Nash Equilibrium and Mixed Actions",
    "text": "Nash Equilibrium and Mixed Actions\n\nMixed Actions\nGiven a game \\(G = (N, (S_i), (u_i))\\) where each player has a finite set of actions \\[\\begin{aligned}\n    S_i = \\{s_i^1, ..., s_i^k\\}\n\\end{aligned}\\]\nA mixed action for player \\(i\\) is a probability measure \\(\\sigma_i: S_i \\to [0,1]\\) such that: \\[\\begin{aligned}\n    \\sigma_i(s_i^1) + \\sigma_i(s_i^2) + ... + \\sigma_i(s_i^k) = 1\n\\end{aligned}\\]\nWe denote \\(\\Sigma_i\\) be the set of mixed actions for player \\(i\\). The cartesian product \\(\\Sigma = \\Sigma_1 \\times ... \\times \\Sigma_n\\) is the set of mixed action profiles.\nThis corresponds to either a player actually randomizes or a player is perceived by other players to be a randomizer.\n\n\nBest Responses\nAn action \\(\\sigma_i^{'} \\in \\Sigma_i\\) is a best response to \\(\\sigma_{-i} \\in \\Sigma_{-i}\\) when: \\[\\begin{aligned}\n    U_i(\\sigma_i^{'}, \\sigma_{-i} ) \\geq U_i(\\sigma_i^{''}, \\sigma_{-i} )\n\\end{aligned}\\] for all \\(\\sigma_i^{''} \\in \\Sigma_i\\).\n\\(B_i(\\sigma_{-i})\\) denotes the set of all best responses to \\(\\sigma_{-i} \\in \\Sigma_{-i}\\).\n\n\nNash Equilibrium\nA profile of mixed actions \\(\\sigma^* \\in \\Sigma\\) is a Nash Equilibrium if, for all \\(i\\), \\[\\begin{aligned}\n      \\sigma_i^* \\in B_i(\\sigma_{-i}^*)\n\\end{aligned}\\]",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro II: Game Theory",
      "Normal-Form Games"
    ]
  },
  {
    "objectID": "repo/micro-g/g1.html#ieda-and-ne-properties",
    "href": "repo/micro-g/g1.html#ieda-and-ne-properties",
    "title": "Normal-Form Games",
    "section": "IEDA and NE: Properties",
    "text": "IEDA and NE: Properties\nIterated Elimination of Dominated Actions (IEDA) and the notion of Nash Equilibrium (NE) are two tools to analyze player strategies in games. Here are some propositions that can be useful in using these two tools.\nProp (1)\nEvery pure strategy Nash Equilibrium \\(s^* = (s_1^*, ..., s_n^*)\\) survives IEDA.\nProp (2)\nSuppose each \\(S_i\\) is a finite set. If IEDA eliminates all but the strategy profile \\(s^* = (s_1^*, ..., s_n^*)\\), then \\(s^*\\) is a pure strategy Nash Equilibrium (by Prop (1), the only pure strategy NE).",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro II: Game Theory",
      "Normal-Form Games"
    ]
  },
  {
    "objectID": "repo/micro-g/g1.html#example-cournots-duopoly-model",
    "href": "repo/micro-g/g1.html#example-cournots-duopoly-model",
    "title": "Normal-Form Games",
    "section": "Example: Cournot’s Duopoly Model",
    "text": "Example: Cournot’s Duopoly Model\nThe setting of this model:\n\nFirm 1 and 2 chooses output \\(q_1\\) and \\(q_2\\) simultaneously (normal-form game) and independently.\n\nMarket sets the price based on production level: \\[\\begin{aligned}\n  P(q_1, q_2) &= \\max[0, 2 - (q_1 + q_2)]\n\\end{aligned}\\]\nWhen assuming unit production cost is 1, profits are:\n\\[\\begin{aligned}\n  \\pi_i &= q_i P(q_i, q_j) - q_i \\\\\n\\end{aligned}\\]\n\nWe can first formally describe this game:\n\n\\(N = \\{1,2\\}\\) be the set of players;\n\\(S_i = \\left[0, +\\infty \\right)\\) be the set of available strategies;\n\\(u_i = q_i (1 - q_i - q_j)\\) be the utility function representing preference relations.\n\nAlthough we can directly solve this using optimization, it is interesting to try out IEDA in a continuous strategy set.\n\n\nClick to Explore\n\nGiven the game setting, we would initially specify the first round of IEDA as:\n\\[\\begin{aligned}\n    S_1^1 = S_2^1 = [0, +\\infty)\n\\end{aligned}\\]\nWe want to find the upper bound of \\(S_i\\) during the second round of IEDA. Let \\(\\overline{q}_i\\) be the upper bound after this round. We would have:\n\\[\\begin{aligned}\n     \\forall k &gt; 0&, \\forall q_2 \\in \\left[0, +\\infty \\right) \\\\\n     u_1(\\overline{q}_1, q_2) &&gt; u_1(\\overline{q}_1 + k, q_2)\\\\\n     \\\\\n    \\implies \\quad \\overline{q}_1 (1 - \\overline{q}_1 - q_2) &&gt; (\\overline{q}_1 + k) (1 - (\\overline{q}_1 + k) - q_2) \\\\\n    \\\\\n    \\implies \\quad \\overline{q}_1 &&gt; \\frac{1 - q_2 - k}{2} \\\\\n    &\\geq \\frac{1 - 0 - 0}{2} = \\frac{1}{2}\n\\end{aligned}\\]\nSimilarly, \\(\\overline{q}_2 \\geq 1/2\\).\nBased on this derivation, I will show that in generic steps, the lower bound \\(l^t\\) and upper bound \\(h^t\\) will converges to the Nash equilibrium.\nGiven \\(0 \\leq l^t &lt; 1/3 &lt; h^t \\leq 1/2\\). First, for upper bound \\(h^t\\): \\[\\begin{aligned}\n     \\forall k &gt; 0&, \\forall q_2 \\in [l^t, h^t] \\\\\n     u_1(h, q_2) &&gt; u_1(h + k, q_2)\\\\\n     \\\\\n    \\implies \\quad h (1 - h - q_2) &&gt; (h + k) (1 - (h + k) - q_2) \\\\\n    \\\\\n    \\implies \\quad h &&gt; \\frac{1 - q_2 - k}{2} \\\\\n    &\\geq \\frac{1 - l^t - 0}{2} = \\frac{1 - l^t}{2}\n\\end{aligned}\\]\nFor lower bound \\(l^t\\), given that \\(h^t \\leq \\frac{1 - l^t}{2}\\), \\[\\begin{aligned}\n    \\forall k &gt; 0&, \\forall q_2 \\in [l^t, \\frac{1 - l^t}{2}] \\\\\n    u_1(l, q_2) &&gt; u_1(l - k, q_2)\\\\\n    \\\\\n    \\implies \\quad l (1 - l - q_2) &&gt; (l - k) (1 - (l - k) - q_2) \\\\\n    \\\\\n    \\implies \\quad l &&lt; \\frac{1 - q_2 - k}{2} \\\\\n    &\\leq \\frac{1 - \\frac{1 - l^t}{2} - 0}{2} = \\frac{1 + l^t}{4}\n\\end{aligned}\\]\nIf \\(l^t\\) converges to \\(\\overline{l}\\) when \\(t \\to + \\infty\\), then: \\[\\begin{aligned}\n    & \\overline{l} = \\frac{1 + \\overline{l}}{4} \\\\\n    \\implies \\quad & \\overline{l} = \\frac{1}{3}\n\\end{aligned}\\]\nIf \\(h^t\\) converges to \\(\\overline{h}\\) when \\(t \\to + \\infty\\), then we would have by substituting \\(\\overline{l} = 1/3\\): \\[\\begin{aligned}\n    & \\overline{h} = \\frac{1 - 1/3}{2} \\\\\n    \\implies \\quad & \\overline{h} = \\frac{1}{3}\n\\end{aligned}\\]\nThis is similarly true for \\(q_2\\). Hence, this gives a Nash equilibrium of: \\[\\begin{aligned}\n    q_1^* = q_2^* = 1/3\n\\end{aligned}\\]",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro II: Game Theory",
      "Normal-Form Games"
    ]
  },
  {
    "objectID": "repo/micro-g/g1.html#example-all-pay-auctions",
    "href": "repo/micro-g/g1.html#example-all-pay-auctions",
    "title": "Normal-Form Games",
    "section": "Example: All-Pay Auctions",
    "text": "Example: All-Pay Auctions\nIn all-pay auctions, all bidders pay for its their own bid and the highest bidder wins. Let’s consider this example to see:\n\nit is strictly dominated that a person bids above its own valuation,\nthere are no pure strategy Nash Equilibrium in this game,\nthere exists one mixed strategy Nash Equilibrium in this game.\n\nSetting:\n\nPlayer A and player B enters the room with initial balance \\(a\\) and \\(b\\) (\\(a, b &gt; 100\\));\nThey are bidding over a one-hundred dollar bill;\nThey only care about the amount of cash they will carry when they leave;\nPlayer A’s vNM utility function for \\(x\\) dollars is \\(u_A(x)\\), player B’s vNM utility function for \\(x\\) dollars is \\(u_B(x)\\). Both functions are strictly increasing and concave (\\(u' &gt; 0, u'' &lt; 0\\)).\n\n\n\nClick to Explore\n\n\nBidding over $100 is strictly dominated.\n\nI argue that bidding over ($100 bid $ \\(100 + k\\) where \\(k &gt; 0\\) is arbitrarily small) is strictly dominated by bidding $ 0 for both players. For Ann: \\[\\begin{aligned}\n  x &=\n  \\begin{cases}\n  a, & b_A = 0\\\\\n  a - k, & b_A = 100 + k \\text{ and A wins}\\\\\n  a - k - 100, & b_A = 100 + k \\text{ and A loses}\\\\\n  \\end{cases}\n  \\\\\n  & \\quad a &gt; a - k &gt; a - 100 - k \\quad \\forall k &gt; 0 \\\\\n  u' &gt; 0 \\implies & u_A(a) &gt; u_A(a-k) &gt; u_A(a-100-k) \\quad \\forall k &gt; 0\n\\end{aligned}\\] Similarly for Bob: \\[\\begin{aligned}\n  u' &gt; 0 \\implies & u_B(b) &gt; u_B(b-k) &gt; B(b-100-k) \\quad \\forall k &gt; 0\n\\end{aligned}\\]\n\nThere are no pure strategy NE.\n\nI argue that there exists no pure Nash eqilibrium. Try that\n\n\\(0 &lt; b_A &lt; b_B \\leq 100\\). A has a profitable deviation of \\(b_A' = b_B\\) to win the auction.\n\\(0 &lt; b_B \\leq b_A \\leq 100\\). B has a profitable deviation of \\(b_B' = 0\\) to minimize loss.\n\\(0 = b_A &lt; b_B \\leq 100\\). B has a profitable deviation of \\(b_B' = 0\\) to minimize loss.\n\\(0 = b_B &lt; b_A \\leq 100\\). A has a profitable deviation of \\(b_A' = 0\\) to win the auction at the lowest cost possible.\n\\(0 = b_B = b_A\\). B has a profitable deviation of \\(b_B' = b_A + \\epsilon, \\forall \\epsilon &gt; 0\\) to win the action.\n\n\nThere exists a mixed strategy NE.\n\nI argue that (\\(F(b_A), F(b_B)\\)), where \\(F: \\BB{R} \\to [0,1]\\) is an uniform c.d.f. of both player, is the mixed Nash equilibrium.\nThe distribution must be uniform throughout the support \\([0, 100]\\) because the indifference condition requires that all bids yield the same expected utility, which is only satisfied when the probability of each bid in the range is spread evenly, ensuring no bid offers a higher or lower payoff than another.\nSince A has \\(a\\) in her pocket already and she is indifferent in placing a bid \\(b_A \\in [0, 100]\\), then she must has a \\(a\\) of expected wealth level. Given that B is randomizing his actions with an uniform distribution \\(b_B \\sim U[0,100]\\): \\[\\begin{aligned}\n  U_A(b_A, F) &= u_A(a - b_A) + u_A(100) \\BB{P}\\{b_B \\leq b_A\\}\\\\\n  &= u_A(a - b_A) + u_A(100) F(b_A)\n\\end{aligned}\\] We need: \\[\\begin{aligned}\n  & u_A(a - b_A) + u_A(100) F(b_A) = u_A(a) \\\\\n  \\implies \\quad & F(b_A) = \\frac{u_A(a) - u_A(a - b_A)}{u_A(100)}\n\\end{aligned}\\] Hence: \\[\\begin{aligned}\n  F(b_A) =\n  \\begin{cases}\n      0 &, b_A &lt; 0 \\\\\n      \\frac{u_A(a) - u_A(a - b_A)}{u_A(100)} &, 0 \\leq b_A \\leq 100 \\\\\n      1 &, b_A &gt; 100\n  \\end{cases}\n\\end{aligned}\\]\nSimilarly for B: \\[\\begin{aligned}\n  F(b_B) =\n  \\begin{cases}\n      0 &, b_B &lt; 0 \\\\\n      \\frac{u_B(b) - u_B(b - b_B)}{u_B(100)} &, 0 \\leq b_B \\leq 100 \\\\\n      1 &, b_B &gt; 100\n  \\end{cases}\n\\end{aligned}\\]\nThus, \\((F(b_A), F(b_B))\\) is a mixed strategy Nash Equilibrium.",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro II: Game Theory",
      "Normal-Form Games"
    ]
  },
  {
    "objectID": "repo/micro-g/g3.html",
    "href": "repo/micro-g/g3.html",
    "title": "Repeated Games",
    "section": "",
    "text": "\\[\n\\def\\BB#1{{\\mathbb{#1}}}\n\\def\\BF#1{{\\mathbf{#1}}}\n\\]",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro II: Game Theory",
      "Repeated Games"
    ]
  },
  {
    "objectID": "repo/micro-g/g3.html#finitely-repeated-games",
    "href": "repo/micro-g/g3.html#finitely-repeated-games",
    "title": "Repeated Games",
    "section": "Finitely Repeated Games",
    "text": "Finitely Repeated Games\nLet\n\\[G = (N, (S_i), (u_i))\\]\nbe a normal-form game.\nIn repeated games, we call \\(G\\) the stage game.\nWe call \\(G(T)\\) the finitely repeated game in which:\n\nthe stage game \\(G\\) is played \\(T\\) times;\noutcomes of all preceding games are observed before next stage game is played;\npreference of each player \\(i \\in N\\) is represented by the sum of payoffs in each stage.\n\nThe how should we define and describe a strategy for player \\(i\\) in repeated games \\(G(T)\\)?\n\nExample: Prisoner’s Dilemma in Repeat\nConsider the stage game \\(G\\):\n\n\n\n\n\\(C\\)\n\\(D\\)\n\n\n\n\n\\(c\\)\n4,4\n0,5\n\n\n\\(d\\)\n5,0\n1,1\n\n\n\nWhat could be the history set \\(H\\) and a strategy of player 1 looks like?\n\n\nClick to Explore\n\n\\[\\begin{aligned}\n  H &= \\{\\emptyset, (c, C), ... , (d, D), ((c, C), (c, C)), ..., ((d, D), (d, D))\\}\n\\end{aligned}\\]\nOne strategy for player 1:\n\n\n\nHistory\nActions\n\n\n\n\n\\(\\emptyset\\)\n\\(c\\)\n\n\n\\((c, C)\\)\n\\(c\\)\n\n\n\\((c, D)\\)\n\\(d\\)\n\n\n\\((d, C)\\)\n\\(d\\)\n\n\n\\((d, D)\\)\n\\(d\\)\n\n\n\nThere are \\(2^5\\) possible strategies for each player.",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro II: Game Theory",
      "Repeated Games"
    ]
  },
  {
    "objectID": "repo/micro-g/g3.html#properties",
    "href": "repo/micro-g/g3.html#properties",
    "title": "Repeated Games",
    "section": "Properties",
    "text": "Properties\n\nUnique NE for Stage Game\nWhenever the stage game \\(G\\) has a unique NE, the unique subgame perfect outcome of \\(G(T)\\) is that NE player in every stage, for every finite \\(T\\).\n\n\nExample: Non-Unique NE for Stage Game\nConsider this stage game \\(G\\):\n\n\n\n\n\\(C\\)\n\\(D\\)\n\\(X\\)\n\n\n\n\n\\(c\\)\n4,4\n0,5\n-1,-1\n\n\n\\(d\\)\n5,0\n1,1\n-1,-1\n\n\n\\(x\\)\n-1,-1\n-1,-1\n3,3\n\n\n\nOne possible SPNE for \\(G(2)\\) would be:\n\n\nClick to Explore\n\nThe strategy for player 1:\n\n\n\nHistory\nActions\n\n\n\n\n\\(\\emptyset\\)\n\\(c\\)\n\n\n\\((c, C)\\)\n\\(x\\)\n\n\nelse\n\\(d\\)\n\n\n\nThe strategy for player 2:\n\n\n\nHistory\nActions\n\n\n\n\n\\(\\emptyset\\)\n\\(C\\)\n\n\n\\((c, C)\\)\n\\(X\\)\n\n\nelse\n\\(D\\)\n\n\n\nOutcome of this repeated game \\(G(2)\\) is: \\(((c, C), (x, X))\\).\nCheck if anyone has a profitable deviation. Without loss of generality, check player 1:\n\n\n\nAction\nPayoff\n\n\n\n\nOriginal Strategy\n7\n\n\nDeviate to \\(d\\) at 1st step\n6\n\n\nDeviate to \\(x\\) at 1st step\n0\n\n\nDeviate to \\(c\\) at 2nd step\n3\n\n\nDeviate to \\(d\\) at 2nd step\n3\n\n\n\nSimilarily true for player 2. Hence this strategy is SPNE.",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro II: Game Theory",
      "Repeated Games"
    ]
  },
  {
    "objectID": "repo/micro-g/g3.html#infinitely-repeated-games",
    "href": "repo/micro-g/g3.html#infinitely-repeated-games",
    "title": "Repeated Games",
    "section": "Infinitely Repeated Games",
    "text": "Infinitely Repeated Games\nStart with a normal-form stage game\n\\[G = (N, (S_i), (u_i)).\\]\nFor each \\(\\delta \\in (0,1)\\) we will create a new game \\(G(\\infty, \\delta)\\) with:\n\n\n\n\n\n\n\nPlayers\n\\(N = \\{1, ..., n\\}\\) same as \\(G\\)\n\n\nStrategies\n\\(\\sigma_i: H \\to \\Delta(S_i)\\) be a set of instructions that directs an action for every possible element of history\n\n\nPreferences\nrepresented by expected payoffs with \\((1-\\delta) \\sum_{t=1}^{\\infty} \\delta^{t-1} u_i (s^t)\\)\n\n\n\n\nCheatsheet: Geometric Sequence Sum\n\\[S_n = a \\frac{1 - r^n}{1 - r}\\]\nwhere\n\n\\(a\\) is the first term of the sequence\n\\(r\\) is the common ratio\n\\(n\\) is the number of terms in the sequence\n\nWhen \\(r \\in (0,1)\\) and \\(n \\to \\infty\\),\n\\[\\lim_{n \\to \\infty} S_n = \\frac{a}{1 - r}\\]\nAn example:\n\\[\\begin{aligned}\n  (1 - \\delta) [2 + 2 \\delta + 2 \\delta^2 + ...] &= (1 - \\delta) \\lim_{n \\to \\infty} [2 + 2 \\delta + ... + 2 \\delta^{n}] \\\\\n  &= \\lim_{n \\to \\infty} (1 - \\delta) 2 \\frac{1 - \\delta^n}{1 - \\delta} \\\\\n  \\delta \\in (0,1) \\implies &= 2\n\\end{aligned}\\]\n\n\nOne-shot Deviation Principle\nProposition\nA strategy profile \\(\\sigma = (\\sigma_i)\\) is a subgame perfect Nash equilibrium of \\(G(\\infty, \\delta)\\) iif there are no profitable one-shot deviations.",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro II: Game Theory",
      "Repeated Games"
    ]
  },
  {
    "objectID": "repo/micro-g/g3.html#common-strategies-for-infinitely-repeated-games",
    "href": "repo/micro-g/g3.html#common-strategies-for-infinitely-repeated-games",
    "title": "Repeated Games",
    "section": "Common Strategies for Infinitely Repeated Games",
    "text": "Common Strategies for Infinitely Repeated Games\nWe would use the example of Repeated Prisoner’s Dilemma.\n\nGrim Trigger\nFor player 1,\n\n\n\n\n\n\n\nHistory\nActions\n\n\n\n\n\\(\\emptyset\\)\n\\(c\\)\n\n\n\\((c, C), ..., (c, C)\\)\n\\(c\\)\n\n\nelse\n\\(d\\)\n\n\n\nSimilar for player 2.\n\n\nTit-for-Tat\nFor player 1,\n\n\n\n\n\n\n\nHistory\nActions\n\n\n\n\n\\(\\emptyset\\)\n\\(c\\)\n\n\n\\(..., (c, C)\\) or \\(..., (d, C)\\)\n\\(c\\)\n\n\n\\(..., (c, D)\\) or \\(..., (d, D)\\)\n\\(d\\)\n\n\n\nFor player 2,\n\n\n\n\n\n\n\nHistory\nActions\n\n\n\n\n\\(\\emptyset\\)\n\\(C\\)\n\n\n\\(..., (c, C)\\) or \\(..., (c, D)\\)\n\\(C\\)\n\n\n\\(..., (d, C)\\) or \\(..., (d, D)\\)\n\\(D\\)",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro II: Game Theory",
      "Repeated Games"
    ]
  },
  {
    "objectID": "repo/micro-g/g5.html",
    "href": "repo/micro-g/g5.html",
    "title": "Perfect Bayesian Equilibrium",
    "section": "",
    "text": "yedlu, Fall 2024\n\n\n\n Back to top",
    "crumbs": [
      "me",
      "Repository",
      "Class Notes",
      "Microeconomics",
      "Micro II: Game Theory",
      "Perfect Bayesian Equilibrium"
    ]
  }
]